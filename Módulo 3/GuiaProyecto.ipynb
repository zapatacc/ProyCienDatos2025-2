{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìò Entrega Final ‚Äî Proyecto en Ciencia de Datos\n",
    "\n",
    "---\n",
    "\n",
    "## 0) üßπ Correcciones de entregas previas (obligatorio, fuera de r√∫brica)\n",
    "- Integrar todas las observaciones de las entregas anteriores.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1) üîÄ Flujo de trabajo Git (rama & PR final)\n",
    "1. Rama final recomendada: `feat/entrega-final`.\n",
    "2. Trabajar exclusivamente en esa rama hasta cerrar la entrega.\n",
    "3. Abrir Pull Request hacia `main` con descripci√≥n clara y detallada.\n",
    "4. Aprobaci√≥n por al menos un integrante adicional.\n",
    "5. Merge limpio (Squash recomendado) para mantener historia clara.\n",
    "6. Mensajes de commit siguiendo Conventional Commits:\n",
    "   - `feat:`, `fix:`, `docs:`, `chore:`, `refactor:`, etc.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2) üìÇ Estructura m√≠nima recomendada del repositorio\n",
    "\n",
    "```text\n",
    "‚îú‚îÄ‚îÄ LICENSE                          # (Opcional) Licencia del proyecto.\n",
    "‚îú‚îÄ‚îÄ README.md                        \n",
    "‚îú‚îÄ‚îÄ pyproject.toml                   # Gesti√≥n de dependencias (usar uno u otro).\n",
    "‚îú‚îÄ‚îÄ data/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ raw/                         # Datos originales (inmutables).\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ interim/                     # Transformaciones intermedias.\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ processed/                   # Dataset final listo para modelar.\n",
    "‚îú‚îÄ‚îÄ notebooks/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ 01_EDA.ipynb                 # Exploraci√≥n profunda de datos.\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ 02_DataWrangling.ipynb       # Limpieza y preparaci√≥n detallada.\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ 03_Experimentos.ipynb        # Entrenamiento, HPO y comparaci√≥n de modelos (incluye secci√≥n training).\n",
    "‚îú‚îÄ‚îÄ Informe Escrito/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ 00_informe_final.ipynb       \n",
    "‚îú‚îÄ‚îÄ src/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ pipelines/\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train_pipeline.py        # Flow Prefect (orquestaci√≥n entrenamiento).\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ backend/\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api.py                   # FastAPI para inferencia del modelo seleccionado.\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt         # Backend-specific Python dependencies.\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile               # Imagen del servicio API.\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ frontend/\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app.py                   # Interfaz Streamlit (visualizaci√≥n y pruebas).\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt         # Frontend-specific Python dependencies.\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile               # Imagen del servicio UI.\n",
    "‚îú‚îÄ‚îÄ docker-compose.yaml              # Orquestaci√≥n de contenedores API + UI.\n",
    "‚îú‚îÄ‚îÄ .env.example                     # Variables de entorno de ejemplo (sin secretos).\n",
    "‚îú‚îÄ‚îÄ .gitignore                       # Ignora artefactos, entornos, datos pesados no necesarios.\n",
    "‚îî‚îÄ‚îÄ docs/\n",
    "    ‚îî‚îÄ‚îÄ screenshots/                 # Capturas de experimentos, model registry, despliegue, API funcionando, UI accesible, etc.\n",
    "```\n",
    "\n",
    "> NOTA `docker-compose`: Verificar rutas de build correctas. Cada servicio debe apuntar al contexto donde vive su respectivo Dockerfile (`./src/backend` y `./src/frontend`). Error com√∫n: usar ra√≠z del repo y no pasar el `WORKDIR` correcto ‚Üí genera im√°genes inconsistente o no encuentra el c√≥digo.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3) üìÑ Contenido esperado en el Informe Final (visi√≥n global)\n",
    "1. Introducci√≥n  \n",
    "2. Antecedentes  \n",
    "3. Objetivos (general y espec√≠ficos)  \n",
    "4. Planteamiento del problema  \n",
    "5. Desarrollo de la soluci√≥n (subsecciones):\n",
    "   - EDA  \n",
    "   - Data Wrangling  \n",
    "   - Entrenamiento y Registro de Experimentos (MLflow+Databricks)  \n",
    "   - Selecci√≥n del Mejor Modelo  \n",
    "   - Orquestaci√≥n (Training Pipeline)  \n",
    "   - Servir el modelo (API FastAPI)  \n",
    "   - Interfaz gr√°fica (Streamlit)  \n",
    "   - Contenerizaci√≥n (Docker / docker-compose)  \n",
    "   - Despliegue en la nube (AWS o HuggingFace Spaces)  \n",
    "6. Conclusiones y recomendaciones  \n",
    "7. Referencias  \n",
    "\n",
    "> El Informe NO duplica el detalle exhaustivo t√©cnico de cada notebook/script; sintetiza hallazgos, decisiones y resultados, y referencia la ruta al notebook o script que contiene el desarrollo completo.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4) üßæ Qu√© se espera en cada secci√≥n (detalle ampliado)\n",
    "\n",
    "### Introducci√≥n\n",
    "- Contexto del dominio (industria/√°rea).\n",
    "- Relevancia del problema (impacto en negocio/sociedad).\n",
    "- Alcance del proyecto (qu√© cubre y qu√© queda fuera).\n",
    "- Breve resumen del dataset (fuente, tama√±o, naturaleza de las variables).\n",
    "\n",
    "### Antecedentes\n",
    "- Trabajos previos, benchmarks, estudios relacionados (2‚Äì6 fuentes).\n",
    "- Resumen de enfoques existentes y brecha identificada.\n",
    "- Justificaci√≥n de por qu√© su aproximaci√≥n a√±ade valor.\n",
    "- Citar fuentes con formato consistente (APA, IEEE o m√≠nimo URL+autor).\n",
    "\n",
    "### Objetivos\n",
    "- Objetivo general: una frase clara y medible.\n",
    "- Objetivos espec√≠ficos (3‚Äì5): cada uno orientado a resultados concretos (ej. \"Construir pipeline reproducible\", \"Evaluar 3 familias de modelos\", \"Dise√±ar API de inferencia\").\n",
    "- Criterios de √©xito: m√©trica principal y umbrales m√≠nimos (ejemplo: F1 ‚â• 0.78 / RMSE ‚â§ 12.0).\n",
    "- Riesgos asociados a los objetivos (disponibilidad de datos, latencia esperada).\n",
    "\n",
    "### Planteamiento del problema\n",
    "- Formulaci√≥n precisa (en formato pregunta o hip√≥tesis).\n",
    "- Variables clave: entradas (features), salida (target), variables auxiliares.\n",
    "- Supuestos y restricciones (ej.: periodicidad, estacionalidad, tama√±o de datos).\n",
    "- Impacto esperado si se soluciona (retorno, eficiencia, usuario final).\n",
    "- Riesgos: calidad de datos, sesgo, interpretaci√≥n, regulaciones.\n",
    "\n",
    "### Desarrollo de la soluci√≥n (subsecciones)\n",
    "\n",
    "#### EDA (An√°lisis Exploratorio de Datos)\n",
    "- Metodolog√≠a: enfoque exploratorio sistem√°tico (distribuciones, correlaciones, segmentaciones).\n",
    "- Hallazgos clave: valores extremos, patrones temporales, relaciones importantes.\n",
    "- Variables candidatas a ingenier√≠a futura.\n",
    "- Visualizaciones clave (incluir 2‚Äì4 en el informe y m√°s en `01_EDA.ipynb`).\n",
    "- Riesgos detectados (data leakage, desequilibrio de clases, missing not at random).\n",
    "\n",
    "#### Data Wrangling\n",
    "- Lista de transformaciones: imputaci√≥n, normalizaci√≥n/escalado, encoding categ√≥rico, manejo de fechas, eliminaci√≥n de duplicados.\n",
    "- Justificaci√≥n de cada transformaci√≥n y alternativas evaluadas.\n",
    "- Evidencias ‚Äúantes/despu√©s‚Äù (peque√±as tablas de ejemplo).\n",
    "- Resultado final: esquema del dataset procesado (columnas, tipos, conteo de filas).\n",
    "- Ruta del dataset final: `data/processed/<nombre>.parquet` / `.csv`.\n",
    "- Referencia t√©cnica completa en `02_DataWrangling.ipynb`.\n",
    "\n",
    "#### Entrenamiento del modelo con MLflow\n",
    "- Familias de modelos entrenadas, m√≠nimo 3 (ej.: √°rbol de decisi√≥n, gradient boosting, modelo lineal regularizado).\n",
    "- Configuraci√≥n base: partici√≥n entrenamiento/validaci√≥n/test y justificaci√≥n.\n",
    "- Registro en MLflow: estructura del experimento, par√°metros loggeados, m√©tricas principales y secundarias.\n",
    "- HPO: librer√≠a usada (Optuna/Hyperopt/Ray/etc.), espacio de b√∫squeda, n√∫mero de evaluaciones, criterio de parada.\n",
    "- Evidencias: screenshot/tabla resumen de mejores runs.\n",
    "- Artifacts registrados: modelo serializado, preprocessor, m√©tricas, diagramas.\n",
    "\n",
    "#### Selecci√≥n del mejor modelo\n",
    "- Criterio objetivo (ej.: minimizar RMSE, maximizar F1).\n",
    "- Comparaci√≥n consolidada: tabla con modelos, hiperpar√°metros clave y m√©tricas (train/valid/test, overfitting signs).\n",
    "- Justificaci√≥n final (balance rendimiento, interpretabilidad, costo en producci√≥n, latencia).\n",
    "- Registro del modelo ganador en el Model Registry (nombre, versi√≥n, alias opcional).\n",
    "\n",
    "#### Orquestaci√≥n ‚Äì Training Pipeline\n",
    "- Descripci√≥n del flujo automatizado con Prefect (o similar):\n",
    "  - Tareas: carga datos ‚Üí preprocesamiento ‚Üí entrenamiento ‚Üí evaluaci√≥n ‚Üí registro ‚Üí notificaci√≥n.\n",
    "- Diagrama simple (texto ASCII o imagen referenciada).\n",
    "- Ejecuci√≥n: comandos para lanzar el pipeline.\n",
    "- Logs y manejo de fallos (reintentos, alertas).\n",
    "\n",
    "#### Servir el modelo (API con FastAPI)\n",
    "- Objetivo del servicio: predicci√≥n bajo demanda / batch.\n",
    "- Endpoints m√≠nimos:\n",
    "  - `GET /health` (estado del servicio).\n",
    "  - `POST /predict` (recibe JSON con features, devuelve predicci√≥n y metadata).\n",
    "- Flujo interno: carga del modelo, preprocesamiento consistente, validaci√≥n de input (pydantic).\n",
    "- Manejo de errores y respuestas (c√≥digos HTTP, mensajes claros).\n",
    "- Ejemplo de request/response JSON en el informe.\n",
    "- Referencia c√≥digo: `src/backend/api.py`.\n",
    "\n",
    "#### Interfaz gr√°fica (Streamlit)\n",
    "- Objetivo: facilitar prueba manual y visualizaci√≥n de resultados.\n",
    "- Componentes m√≠nimos:\n",
    "  - Formulario para ingresar par√°metros.\n",
    "  - Bot√≥n de ‚ÄúPredecir‚Äù que llama a la API.\n",
    "- Indicaciones de ejecuci√≥n local: `streamlit run src/frontend/app.py`.\n",
    "- Referencia c√≥digo: `src/frontend/app.py`.\n",
    "\n",
    "#### Contenerizaci√≥n del servicio (Docker)\n",
    "- Dockerfile backend:\n",
    "  - Instalar dependencias m√≠nimas.\n",
    "  - Copiar c√≥digo.\n",
    "  - Ejecutar con `uvicorn`.\n",
    "- Dockerfile frontend:\n",
    "  - Instalar dependencias y lanzar streamlit.\n",
    "- Optimizaci√≥n recomendada: usar im√°genes base slim.\n",
    "- `docker-compose.yaml`:\n",
    "  - Servicios: `backend`, `frontend`.\n",
    "- NOTA IMPORTANTE: Revisar paths de `build` y `context` en compose para evitar apuntar a la ra√≠z sin necesidad y perder acceso a archivos.\n",
    "\n",
    "#### Despliegue del servicio en la nube (AWS o HuggingFace Spaces)\n",
    "- Elegir plataforma:\n",
    "  - AWS (EC2/ECS/EKS/Lambda + S3) o HuggingFace Spaces (m√°s r√°pido para prototipos).\n",
    "- Documentar pasos.\n",
    "- Capturas requeridas:\n",
    "  - Pantalla del servicio corriendo.\n",
    "- Limpieza / costos: pasos para detener recursos si es AWS.\n",
    "\n",
    "### Conclusiones y recomendaciones\n",
    "- S√≠ntesis de lo logrado, aprendizajes, limitaciones y l√≠neas futuras (mejora de features, retraining, escalado).\n",
    "\n",
    "### Referencias\n",
    "- Lista organizada y consistente (formato √∫nico).\n",
    "- Incluir documentaci√≥n de librer√≠as cr√≠ticas (FastAPI, Prefect, MLflow, HPO).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 5) üß© Notebooks vs Informe (regla de oro)\n",
    "- Notebooks: c√≥digo detallado, exploraciones, gr√°ficos completos, experimentos exhaustivos.\n",
    "- Informe: narrativa resumida, decisiones, enlaces directos a notebooks/scripts.\n",
    "- Cada subsecci√≥n del ‚ÄúDesarrollo de la soluci√≥n‚Äù debe contener:  \n",
    "  ‚ÄúDetalle t√©cnico completo: ver `notebooks/<X>.ipynb`‚Äù o ‚Äúver `src/<ruta>.py`‚Äù.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 6) üöÄ R√∫brica de evaluaci√≥n (100 pts)\n",
    "- Claridad de datos & m√©trica ‚Äî 10 pts  \n",
    "- Preprocesamiento bien definido ‚Äî 10 pts  \n",
    "- 3+ modelos con HPO y MLflow (evidencia) ‚Äî 25 pts  \n",
    "- Selecci√≥n del mejor modelo justificada ‚Äî 10 pts  \n",
    "- Registro en Model Registry y documentaci√≥n ‚Äî 20 pts  \n",
    "- Evidencias reproducibles y PR conformes ‚Äî 10 pts  \n",
    "- Calidad del Informe (estructura, s√≠ntesis y referencias) ‚Äî 15 pts  \n",
    "\n",
    "> Las correcciones previas son requisito, no puntaje.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) ‚úÖ Checklist final (para el PR)\n",
    "- [ ] Informe final (`00_informe_final.ipynb` o PDF) con s√≠ntesis y referencias a notebooks/scripts.\n",
    "- [ ] `01_EDA.ipynb` completo y ejecutable.\n",
    "- [ ] `02_DataWrangling.ipynb` con transformaciones reproducibles.\n",
    "- [ ] `03_Experimentos.ipynb` con entrenamiento, HPO y comparaci√≥n de modelos.\n",
    "- [ ] Modelo campe√≥n registrado en Model Registry.\n",
    "- [ ] `src/pipelines/train_pipeline.py` funcionando (orquestaci√≥n).\n",
    "- [ ] API en `src/backend/api.py` lista (endpoints definidos).\n",
    "- [ ] UI en `src/frontend/app.py` funcionando localmente.\n",
    "- [ ] Dockerfiles backend + frontend construyen correctamente.\n",
    "- [ ] `docker-compose.yaml` probado (paths y context verificados).\n",
    "- [ ] Despliegue en AWS o HuggingFace Space con screenshots en `docs/screenshots/`.\n",
    "- [ ] README con instrucciones de reproducci√≥n (entorno, comandos, inferencia).\n",
    "- [ ] PR `feat/entrega-final` ‚Üí `main` aprobado y mergeado.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 8) üß∑ Recomendaciones finales\n",
    "- Usar `.env.example` para guiar configuraci√≥n sin exponer secretos.\n",
    "- Mantener dependencias limpias y fijar versiones cr√≠ticas (MLflow, Prefect, FastAPI).\n",
    "- Validar consistencia entre preprocesamiento en entrenamiento y en inferencia.\n",
    "- Minimizar peso de la imagen Docker (limpiar caches, usar `--no-cache-dir`).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 2 Presentaci√≥n.\n",
    "> Recuerden que la nota del proyecto es mitad el trabajo, y mitad la presentaci√≥n. Deben hacer una presentaci√≥n en power point para presentar el trabajo en la clase. La presentaci√≥n, adem√°s de llevar todos los componentes b√°sicos descritos en el entregable, debe llevar una tabla de contenido.\n",
    ">\n",
    "> - Presentaci√≥n: 25 minutos.\n",
    "> - Seguir estas recomendaciones:\n",
    "    > - https://www.ncsl.org/legislative-staff/lscc/tips-for-making-effective-powerpoint-presentations\n",
    "    > - https://www.trentu.ca/academicskills/how-guides/how-write-university/how-approach-any-assignment/creating-effective-powerpoint-slides"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
