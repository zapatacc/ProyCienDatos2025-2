{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1792ca886606664",
   "metadata": {},
   "source": [
    "# 0. Introducci√≥n a Cron y Logger en Python\n",
    "\n",
    "## 0.1. ¬øQu√© es **Cron**?\n",
    "\n",
    "https://en.wikipedia.org/wiki/Cron\n",
    "\n",
    "La utilidad de l√≠nea de comandos **cron** es un **programador de tareas** (job scheduler) en sistemas operativos basados en `Unix`. Su funci√≥n es permitir a los usuarios, quienes mantienen y configuran entornos de software, programar trabajos (jobs), como comandos o scripts de shell, conocidos tambi√©n como **cron jobs**, para ejecutarse peri√≥dicamente en tiempos, fechas o intervalos fijos.\n",
    "\n",
    "Cron se utiliza t√≠picamente para automatizar tareas de mantenimiento o administraci√≥n del sistema. Sin embargo, su naturaleza general lo hace √∫til para otras actividades, como descargar archivos desde Internet o revisar correos electr√≥nicos a intervalos regulares. \n",
    "\n",
    "**Cron** es m√°s adecuado para tareas repetitivas.\n",
    "\n",
    "El nombre de **cron** proviene de \"Chronos\", la palabra griega para tiempo.\n",
    "\n",
    "```bash\n",
    "# * * * * * <command to execute>\n",
    "# | | | | |\n",
    "# | | | | day of the week (0‚Äì6) (Sunday to Saturday; 7 is also Sunday on some systems)\n",
    "# | | | month (1‚Äì12)             \n",
    "# | | day of the month (1‚Äì31)\n",
    "# | hour (0‚Äì23)\n",
    "# minute (0‚Äì59)\n",
    "```\n",
    "\n",
    "### Vamos a jugar\n",
    "https://crontab.guru/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100dcd94c5871c6f",
   "metadata": {},
   "source": [
    "## 0.2. ¬øQu√© es **Logger** en Python?\n",
    "\n",
    "A medida que nuestros scripts se vuelven m√°s complejos, necesitamos una forma de **monitorear** lo que est√° sucediendo en ellos, especialmente cuando algo sale mal. Aqu√≠ es donde entra **logging**. \n",
    "\n",
    "`Python` tiene un m√≥dulo integrado llamado `logging` que permite registrar eventos o mensajes en diferentes niveles: \n",
    "\n",
    "- **DEBUG**: Informaci√≥n detallada, usualmente para desarrolladores.\n",
    "- **INFO**: Confirmaci√≥n de que las cosas est√°n funcionando como se esperaba.\n",
    "- **WARNING**: Algo inesperado, pero no cr√≠tico.\n",
    "- **ERROR**: Fallos debido a un problema en el programa.\n",
    "- **CRITICAL**: Error grave, usualmente detiene el programa.\n",
    "\n",
    "Para usar **logger** en un script de Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cf3da74964194d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-27 20:27:08,380 - DEBUG - Este es un mensaje de depuraci√≥n\n",
      "2025-10-27 20:27:08,381 - INFO - Este es un mensaje informativo\n",
      "2025-10-27 20:27:08,382 - WARNING - Este es una advertencia\n",
      "2025-10-27 20:27:08,382 - ERROR - Este es un mensaje de error\n",
      "2025-10-27 20:27:08,383 - CRITICAL - Este es un error cr√≠tico\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# Configuraci√≥n b√°sica de logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG, \n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    ")\n",
    "\n",
    "# Ejemplo de c√≥mo registrar eventos\n",
    "logging.debug(\"Este es un mensaje de depuraci√≥n\")\n",
    "logging.info(\"Este es un mensaje informativo\")\n",
    "logging.warning(\"Este es una advertencia\")\n",
    "logging.error(\"Este es un mensaje de error\")\n",
    "logging.critical(\"Este es un error cr√≠tico\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ee57a2a84eb1a8",
   "metadata": {},
   "source": [
    "### Configuraci√≥n de **Logger** en Python\n",
    "\n",
    "El m√≥dulo `logging` de Python permite una gran flexibilidad para definir c√≥mo y d√≥nde se registran los mensajes. Algunas de las configuraciones m√°s comunes son:\n",
    "\n",
    "#### 1. **Nivel de Log** (`level`)\n",
    "El nivel del log define la gravedad de los mensajes que se quieren capturar. Algunos niveles de log comunes incluyen:\n",
    "- `DEBUG`: Informaci√≥n detallada, √∫til para depuraci√≥n.\n",
    "- `INFO`: Confirmaciones de que el programa est√° funcionando como se espera.\n",
    "- `WARNING`: Indica que algo inesperado sucedi√≥, pero el programa sigue funcionando.\n",
    "- `ERROR`: Se√±ala errores m√°s graves, pero que no detienen la ejecuci√≥n.\n",
    "- `CRITICAL`: Errores graves que probablemente detendr√°n el programa.\n",
    "\n",
    "Cuando configuramos un **nivel de log**, s√≥lo se capturan los mensajes de ese nivel o superiores. Por ejemplo, si establecemos el nivel en `WARNING`, se registrar√°n los mensajes `WARNING`, `ERROR` y `CRITICAL`, pero no los `DEBUG` o `INFO`.\n",
    "\n",
    "#### 2. **Formato del mensaje** (`format`)\n",
    "El formato del mensaje permite personalizar c√≥mo se muestran los logs. Algunos componentes √∫tiles en el formato son:\n",
    "- `%(asctime)s`: La fecha y hora en que se registr√≥ el mensaje.\n",
    "- `%(levelname)s`: El nivel del log (DEBUG, INFO, WARNING, etc.).\n",
    "- `%(message)s`: El mensaje que se ha registrado.\n",
    "- `%(name)s`: El nombre del logger.\n",
    "- `%(threadName)s`: El nombre del hilo desde donde se emiti√≥ el log.\n",
    "- `%(processName)s`: El nombre del proceso que emiti√≥ el log.\n",
    "\n",
    "#### 3. **Formato de fecha y hora** (`datefmt`)\n",
    "El par√°metro `datefmt` permite personalizar el formato de la fecha y hora que se incluye en los mensajes de log. Puedes usar cualquier formato de fecha y hora compatible con Python, como el que se usa en `strftime`. Esto es √∫til para ajustar el formato a las necesidades espec√≠ficas de tu aplicaci√≥n.\n",
    "\n",
    "##### C√≥digos de Formato Comunes\n",
    "\n",
    "Aqu√≠ tienes algunos c√≥digos de formato com√∫nmente utilizados que puedes usar con `strftime`:\n",
    "\n",
    "| C√≥digo | Significado                           | Ejemplo de Salida       |\n",
    "|--------|---------------------------------------|--------------------------|\n",
    "| `%Y`   | A√±o con siglo                         | `2024`                   |\n",
    "| `%y`   | A√±o sin siglo (00-99)                | `24`                     |\n",
    "| `%m`   | Mes como un decimal con ceros (01-12)| `09`                     |\n",
    "| `%B`   | Nombre completo del mes               | `Septiembre`             |\n",
    "| `%b`   | Nombre abreviado del mes              | `Sep`                    |\n",
    "| `%d`   | D√≠a del mes (01-31)                  | `24`                     |\n",
    "| `%H`   | Hora (00-23)                         | `14`                     |\n",
    "| `%I`   | Hora (01-12)                         | `02`                     |\n",
    "| `%M`   | Minuto (00-59)                       | `05`                     |\n",
    "| `%S`   | Segundo (00-59)                      | `30`                     |\n",
    "| `%p`   | AM o PM                              | `PM`                     |\n",
    "| `%A`   | Nombre completo del d√≠a de la semana | `Martes`                 |\n",
    "| `%a`   | Nombre abreviado del d√≠a de la semana | `Mar`                    |\n",
    "| `%j`   | D√≠a del a√±o (001-366)                | `267`                    |\n",
    "| `%U`   | N√∫mero de semana del a√±o (00-53)     | `39`                     |\n",
    "| `%W`   | N√∫mero de semana del a√±o (00-53), basado en lunes | `39`          |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb84a8ef7326c9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-27 20:36:27,948 - INFO - Respaldo iniciado\n",
      "2025-10-27 20:36:27,950 - ERROR - Error: La base de datos no existe\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "                           \n",
    "logging.basicConfig(\n",
    "    # filename='backup.log', \n",
    "    level=logging.INFO, \n",
    "    format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n",
    "     datefmt='%Y-%m-%d %H:%M:%S',\n",
    ")\n",
    "\n",
    "def hacer_respaldo():\n",
    "    try:\n",
    "        # Supongamos que aqu√≠ ocurre el proceso de respaldo\n",
    "        logger.info(\"Respaldo iniciado\")\n",
    "        # Simulaci√≥n de respaldo\n",
    "        if os.path.exists('base_de_datos.db'):\n",
    "            logger.info(\"Respaldo exitoso\")\n",
    "        else:\n",
    "            logger.error(\"Error: La base de datos no existe\")\n",
    "    except Exception as e:\n",
    "        logger.critical(f\"Error cr√≠tico durante el respaldo: {e}\")\n",
    "\n",
    "# Ejecutamos la funci√≥n\n",
    "hacer_respaldo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d614b0b6d3b18ce7",
   "metadata": {},
   "source": [
    "Ahora s√≠, empecemos la clase de hoy\n",
    "\n",
    "# 1. Machine Learning Pipeline a.k.a Workflow Orchestration\n",
    "\n",
    "> Un pipeline de machine learning es una serie de pasos secuenciales y automatizados que se siguen para entrenar, evaluar y desplegar un modelo de machine learning. \n",
    "> El objetivo principal de un pipeline es automatizar el proceso repetitivo de transformar datos crudos en un modelo que pueda usarse en producci√≥n.\n",
    "\n",
    "    \n",
    "### Yo tratando de explicar el orden de ejecuci√≥n de las celdas de mi `jupyter-notebook`:\n",
    "\n",
    " <img style=\"display: block; margin: auto;\" src=\"./images/orchestration-meme.png\" width=\"580\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e8ef3c5d729af1",
   "metadata": {},
   "source": [
    "Revisemos lo que hemos hecho hasta ahora con nuestro c√≥digo...\n",
    "1. Downloading data ----> Ingestion\n",
    "2. Transforming the data ----> Filtering, removing outliers\n",
    "3. Preparing data for ML ----> Feature Engineering\n",
    "4. Hyper-parameter tunning ----> Best params\n",
    "5. Train the final model ----> Best params\n",
    "6. Registry the final model\n",
    "\n",
    "**Problemas:**\n",
    "- Un cuaderno gigante\n",
    "- Sin muchas instrucciones\n",
    "- Poco legible para cualquier persona\n",
    "- No escalable ni mantenible\n",
    "- Podr√≠amos decir que es un `workflow`, ya que se debe ejecutar en un orden espec√≠fico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def download_data(year, month):\n",
    "    ...\n",
    "    return df\n",
    "\n",
    "def prepare_data(df):\n",
    "    ...\n",
    "    return df\n",
    "\n",
    "def feature_engineering(df):\n",
    "    ...\n",
    "    return X, y\n",
    "\n",
    "def find_best_model(X, y):\n",
    "    ...\n",
    "    return params\n",
    "\n",
    "def train_model(X, y, params):\n",
    "    ...\n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    df = download_data(2024,1)\n",
    "    df = prepare_data(df)\n",
    "    X, y = feature_engineering(df)\n",
    "    model_params = find_best_model(X, y)\n",
    "    model = train_model(X, y, model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37b404890b7646d",
   "metadata": {},
   "source": [
    "Mucho mejor, no?\n",
    "\n",
    "Pero sigue teniendo problemas:\n",
    "- Lo podemos agendar?\n",
    "- Qu√© pasa si tengo m√∫ltiples archivos?\n",
    "- O si no lo quiero ejecutar en mi m√°quina local?\n",
    "- Qu√© pasa si una de las funciones falla? Si es solamente temporal el fallo?\n",
    "- Y si queremos notificar que ese error ocurri√≥ a alg√∫n administrador?\n",
    "\n",
    "Hay m√∫ltiples herramientas que vienen a solventar esos problemas:\n",
    "\n",
    "- [Apache Airflow](https://airflow.apache.org/)\n",
    "- [Prefect](https://www.prefect.io/)\n",
    "- [Mage](https://www.mage.ai/)\n",
    "- [Dagster](https://dagster.io/)\n",
    "- [Kubeflow Pipelines](https://www.kubeflow.org/docs/components/pipelines/)\n",
    "- [Scikitlearn Pipelines](https://scikit-learn.org/stable/modules/compose.html#pipeline)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eaecb1d50d0eb2",
   "metadata": {},
   "source": [
    "# 2. Prefect\n",
    "\n",
    "## 2.1. Definiciones en **Prefect**\n",
    "\n",
    "### 2.1.1. **Task (Tarea)**\n",
    "https://docs.prefect.io/3.0/develop/write-tasks\n",
    "\n",
    "En **Prefect**, una `task` es la unidad m√°s b√°sica de trabajo en un flujo de Prefect. Una `task` representa una operaci√≥n individual que se ejecuta dentro de un flujo de trabajo (`flow`). Puedes convertir cualquier funci√≥n de Python en una `task` agregando el decorador `@task`. \n",
    "\n",
    "Las tasks pueden:\n",
    "- **Tomar entradas, realizar un trabajo y devolver salidas**: Realizan operaciones con los datos que reciben y devuelven resultados.\n",
    "- **Cachear su ejecuci√≥n a trav√©s de m√∫ltiples invocaciones**: Evitar repetir c√°lculos si una task ya se ejecut√≥ anteriormente con los mismos inputs.\n",
    "- **Encapsular la l√≥gica del flujo en unidades reutilizables**: Pueden ser utilizadas en diferentes flows.\n",
    "- **Usar logging autom√°tico** para capturar detalles de ejecuci√≥n, etiquetas (tags) y estado final.\n",
    "- **Ejecutarse de forma concurrente**: Permiten paralelismo en la ejecuci√≥n de tareas.\n",
    "- **Definirse en el mismo archivo que el `flow` o importarse de m√≥dulos**.\n",
    "- **Llamarse desde `flows` u otras `tasks`**.\n",
    "\n",
    "**Ejemplo de una tarea:**\n",
    "\n",
    "```python\n",
    "from prefect import task\n",
    "\n",
    "@task\n",
    "def sumar(a, b):\n",
    "    return a + b\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d69588b800985b",
   "metadata": {},
   "source": [
    "### 2.1.2. **Flow (Flujo)**\n",
    "https://docs.prefect.io/3.0/develop/write-flows\n",
    "\n",
    "Un `flow` en **Prefect** es una colecci√≥n de `tasks` que se ejecutan de manera organizada y coordinada. \n",
    "\n",
    "Un `flow` define c√≥mo las `tasks` interact√∫an entre s√≠ y permite orquestar la ejecuci√≥n de m√∫ltiples `tasks` con reglas espec√≠ficas, como dependencias, condicionales y paralelismo. \n",
    "\n",
    "Adem√°s, un `flow` puede manejar `tasks` de manera secuencial o en paralelo, as√≠ como gestionarlas en funci√≥n de eventos externos.\n",
    "\n",
    "Los flows se definen como funciones en Python, y pueden tomar entradas, realizar tareas y devolver resultados. Cualquier funci√≥n Python puede convertirse en un flow de Prefect a√±adiendo el decorador `@flow`:\n",
    "```python\n",
    "from prefect import flow\n",
    "\n",
    "@flow\n",
    "def mi_flujo_principal():\n",
    "    resultado = sumar(3, 4)\n",
    "    print(f\"El resultado es {resultado}\")\n",
    "```\n",
    "#### Capacidades de los Flows en Prefect:\n",
    "\n",
    "Cuando una funci√≥n se convierte en un `flow`, adquiere las siguientes capacidades:\n",
    "\n",
    "- **Seguimiento autom√°tico de metadatos** sobre las ejecuciones del flujo, como el tiempo de ejecuci√≥n y el estado final.\n",
    "- **Registro de cada estado** que el flujo alcanza, lo que permite observar y actuar sobre cada transici√≥n en la ejecuci√≥n del flow.\n",
    "- **Validaci√≥n de tipos de los argumentos** de entrada como par√°metros del flujo de trabajo.\n",
    "- **Reintentos autom√°ticos** en caso de fallo, con l√≠mites y retrasos configurables.\n",
    "- **Timeouts** para evitar que los flujos de trabajo se ejecuten durante demasiado tiempo sin control.\n",
    "- **Capacidad de despliegue**, lo que expone una API para interactuar con el flow de manera remota.\n",
    "\n",
    "Los `flows` se identifican de forma √∫nica por su nombre. Puedes especificar un nombre para el `flow` utilizando el par√°metro `name`:\n",
    "\n",
    "```python\n",
    "@flow(name=\"Mi Flujo\")\n",
    "def mi_flujo() -> str:\n",
    "    return \"¬°Hola, mundo!\"\n",
    "```\n",
    "\n",
    "Si no proporcionas un nombre, Prefect usar√° el nombre de la funci√≥n del flow.\n",
    "\n",
    "#### Ejecuci√≥n de `Flows`:\n",
    "\n",
    "Una ejecuci√≥n de flow (**flow run**) es una ejecuci√≥n individual de un `flow`.\n",
    "\n",
    "Puedes ejecutar un `flow` llam√°ndolo por su nombre de funci√≥n, de la misma manera que lo har√≠as con una funci√≥n normal de `Python`. Tambi√©n puedes ejecutar un `flow` mediante:\n",
    "\n",
    "- **Programadores externos**, como `cron`, para invocar la funci√≥n del `flow`.\n",
    "- **Desplegar el flow en Prefect Cloud** o en un servidor auto-hospedado de Prefect.\n",
    "- **Iniciar una ejecuci√≥n de flow a trav√©s de un cronograma**, la interfaz de usuario de Prefect, o la API de Prefect.\n",
    "\n",
    "Sin importar c√≥mo ejecutes el `flow`, `Prefect` monitorea su ejecuci√≥n, capturando el estado para observabilidad. Adem√°s, puedes registrar una variedad de metadatos sobre las ejecuciones del flow para monitoreo, resoluci√≥n de problemas y auditor√≠a."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edee0e98d84bbc0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 2.1.3. Diferencias entre `Task` y `Flow`:\n",
    "\n",
    "- **Task**: Una tarea individual, peque√±a y espec√≠fica que ejecuta una operaci√≥n.\n",
    "- **Flow**: Un contenedor que organiza y coordina la ejecuci√≥n de varias tasks, permitiendo su orquestaci√≥n.\n",
    "\n",
    "### 2.1.4. Ejemplo Completo de Task y Flow en Prefect:\n",
    "\n",
    "```python\n",
    "from prefect import task, flow\n",
    "\n",
    "@task\n",
    "def sumar(a, b):\n",
    "    return a + b\n",
    "\n",
    "@flow\n",
    "def mi_flujo_principal():\n",
    "    resultado = sumar(3, 4)\n",
    "    print(f\"El resultado es {resultado}\")\n",
    "\n",
    "# Ejecutar el flow\n",
    "mi_flujo_principal()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117d1c873fd6836e",
   "metadata": {},
   "source": [
    "## 2.2 Uso de `Prefect`\n",
    "\n",
    "```bash\n",
    "uv add prefect\n",
    "prefect version\n",
    "```\n",
    "\n",
    "Ahora vamos a inicializar un servidor de `prefect`\n",
    "\n",
    "```bash\n",
    "prefect server start\n",
    "```\n",
    "\n",
    "Vamos a ver un `flow` sencillo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e81b69181ae7d5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T07:48:48.690700Z",
     "start_time": "2024-09-24T07:48:46.007790Z"
    }
   },
   "outputs": [],
   "source": [
    "import httpx\n",
    "from prefect import flow, task\n",
    "\n",
    "\n",
    "@task(retries=4, retry_delay_seconds=1, log_prints=True)\n",
    "def fetch_cat_fact():\n",
    "    cat_fact = httpx.get(\"https://f3-vyx5c2hfpq-ue.a.run.app/\")\n",
    "    #An endpoint that is designed to fail sporadically\n",
    "    if cat_fact.status_code >= 400:\n",
    "        raise Exception()\n",
    "    print(cat_fact.text)\n",
    "\n",
    "\n",
    "@flow\n",
    "def fetch():\n",
    "    fetch_cat_fact()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30e522a6a8473229",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T07:49:36.657027Z",
     "start_time": "2024-09-24T07:49:31.673396Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-27 21:19:43,866 - DEBUG - connect_tcp.started host='127.0.0.1' port=4200 local_address=None timeout=60.0 socket_options=None\n",
      "2025-10-27 21:19:43,868 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1137aec00>\n",
      "2025-10-27 21:19:43,870 - DEBUG - send_request_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:19:43,871 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:19:43,878 - DEBUG - send_request_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:19:43,879 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:19:43,879 - DEBUG - receive_response_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:19:43,881 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Tue, 28 Oct 2025 03:19:43 GMT'), (b'server', b'uvicorn'), (b'content-length', b'8'), (b'content-type', b'application/json')])\n",
      "2025-10-27 21:19:43,882 - INFO - HTTP Request: GET http://127.0.0.1:4200/api/admin/version \"HTTP/1.1 200 OK\"\n",
      "2025-10-27 21:19:43,883 - DEBUG - receive_response_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:19:43,884 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:19:43,885 - DEBUG - response_closed.started\n",
      "2025-10-27 21:19:43,886 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:19:43,888 - DEBUG - send_request_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:19:43,889 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:19:43,890 - DEBUG - send_request_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:19:43,892 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:19:43,893 - DEBUG - receive_response_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:19:43,895 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 422, b'Unprocessable Entity', [(b'date', b'Tue, 28 Oct 2025 03:19:43 GMT'), (b'server', b'uvicorn'), (b'content-length', b'41'), (b'content-type', b'application/json')])\n",
      "2025-10-27 21:19:43,898 - INFO - HTTP Request: GET http://127.0.0.1:4200/api/csrf-token?client=07d9d18c-a5da-4abc-ab42-9121eb332e31 \"HTTP/1.1 422 Unprocessable Entity\"\n",
      "2025-10-27 21:19:43,903 - DEBUG - receive_response_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:19:43,905 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:19:43,906 - DEBUG - response_closed.started\n",
      "2025-10-27 21:19:43,907 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:19:43,908 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:19:43,909 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:19:43,909 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:19:43,911 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:19:43,912 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:19:43,922 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Tue, 28 Oct 2025 03:19:43 GMT'), (b'server', b'uvicorn'), (b'content-length', b'162'), (b'content-type', b'application/json')])\n",
      "2025-10-27 21:19:43,923 - INFO - HTTP Request: POST http://127.0.0.1:4200/api/flows/ \"HTTP/1.1 200 OK\"\n",
      "2025-10-27 21:19:43,925 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:19:43,926 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:19:43,928 - DEBUG - response_closed.started\n",
      "2025-10-27 21:19:43,930 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:19:43,932 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:19:43,934 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:19:43,935 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:19:43,935 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:19:43,936 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:19:43,957 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 201, b'Created', [(b'date', b'Tue, 28 Oct 2025 03:19:43 GMT'), (b'server', b'uvicorn'), (b'content-length', b'698'), (b'content-type', b'application/json'), (b'vary', b'Accept-Encoding'), (b'content-encoding', b'gzip')])\n",
      "2025-10-27 21:19:43,958 - INFO - HTTP Request: POST http://127.0.0.1:4200/api/flow_runs/ \"HTTP/1.1 201 Created\"\n",
      "2025-10-27 21:19:43,959 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:19:43,960 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:19:43,962 - DEBUG - response_closed.started\n",
      "2025-10-27 21:19:43,964 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:19:43,971 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:19:43,972 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:19:43,973 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:19:43,975 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:19:43,975 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:19:43,991 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 201, b'Created', [(b'date', b'Tue, 28 Oct 2025 03:19:43 GMT'), (b'server', b'uvicorn'), (b'content-length', b'411'), (b'content-type', b'application/json'), (b'vary', b'Accept-Encoding'), (b'content-encoding', b'gzip')])\n",
      "2025-10-27 21:19:43,991 - INFO - HTTP Request: POST http://127.0.0.1:4200/api/flow_runs/0260d32e-24a2-4bc0-8650-714e29321b2c/set_state \"HTTP/1.1 201 Created\"\n",
      "2025-10-27 21:19:43,992 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:19:43,993 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:19:43,995 - DEBUG - response_closed.started\n",
      "2025-10-27 21:19:43,995 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:19:43,997 - DEBUG - send_request_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:19:43,998 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:19:43,998 - DEBUG - send_request_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:19:43,999 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:19:44,000 - DEBUG - receive_response_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:19:44,006 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Tue, 28 Oct 2025 03:19:43 GMT'), (b'server', b'uvicorn'), (b'content-length', b'737'), (b'content-type', b'application/json'), (b'vary', b'Accept-Encoding'), (b'content-encoding', b'gzip')])\n",
      "2025-10-27 21:19:44,007 - INFO - HTTP Request: GET http://127.0.0.1:4200/api/flow_runs/0260d32e-24a2-4bc0-8650-714e29321b2c \"HTTP/1.1 200 OK\"\n",
      "2025-10-27 21:19:44,007 - DEBUG - receive_response_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:19:44,009 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:19:44,045 - DEBUG - response_closed.started\n",
      "2025-10-27 21:19:44,047 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:19:44,054 - INFO - Beginning flow run 'stoic-pelican' for flow 'fetch'\n",
      "2025-10-27 21:19:44,057 - INFO - View at http://127.0.0.1:4200/runs/flow-run/0260d32e-24a2-4bc0-8650-714e29321b2c\n",
      "2025-10-27 21:19:44,115 - DEBUG - connect_tcp.started host='f3-vyx5c2hfpq-ue.a.run.app' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2025-10-27 21:19:44,136 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x113897aa0>\n",
      "2025-10-27 21:19:44,137 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x11386cc50> server_hostname='f3-vyx5c2hfpq-ue.a.run.app' timeout=5.0\n",
      "2025-10-27 21:19:44,177 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1041a0620>\n",
      "2025-10-27 21:19:44,178 - DEBUG - send_request_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:19:44,179 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:19:44,180 - DEBUG - send_request_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:19:44,181 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:19:44,182 - DEBUG - receive_response_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:19:44,444 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 500, b'Internal Server Error', [(b'content-type', b'text/html; charset=utf-8'), (b'x-cloud-trace-context', b'03f8c2c47a051b547221894edcda91d2;o=1'), (b'date', b'Tue, 28 Oct 2025 03:19:44 GMT'), (b'server', b'Google Frontend'), (b'Content-Length', b'181'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000')])\n",
      "2025-10-27 21:19:44,445 - INFO - HTTP Request: GET https://f3-vyx5c2hfpq-ue.a.run.app/ \"HTTP/1.1 500 Internal Server Error\"\n",
      "2025-10-27 21:19:44,446 - DEBUG - receive_response_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:19:44,447 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:19:44,448 - DEBUG - response_closed.started\n",
      "2025-10-27 21:19:44,449 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:19:44,450 - DEBUG - close.started\n",
      "2025-10-27 21:19:44,451 - DEBUG - close.complete\n",
      "2025-10-27 21:19:44,456 - INFO - Task run failed with exception: Exception() - Retry 1/4 will start 1 second(s) from now\n",
      "2025-10-27 21:19:45,475 - DEBUG - connect_tcp.started host='f3-vyx5c2hfpq-ue.a.run.app' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2025-10-27 21:19:45,495 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1138840b0>\n",
      "2025-10-27 21:19:45,495 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x11385c7d0> server_hostname='f3-vyx5c2hfpq-ue.a.run.app' timeout=5.0\n",
      "2025-10-27 21:19:45,537 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x113884620>\n",
      "2025-10-27 21:19:45,538 - DEBUG - send_request_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:19:45,539 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:19:45,540 - DEBUG - send_request_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:19:45,540 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:19:45,541 - DEBUG - receive_response_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:19:45,643 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 500, b'Internal Server Error', [(b'content-type', b'text/html; charset=utf-8'), (b'x-cloud-trace-context', b'5e4aae0078b90e96ba8c239bd873872d'), (b'date', b'Tue, 28 Oct 2025 03:19:45 GMT'), (b'server', b'Google Frontend'), (b'Content-Length', b'181'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000')])\n",
      "2025-10-27 21:19:45,644 - INFO - HTTP Request: GET https://f3-vyx5c2hfpq-ue.a.run.app/ \"HTTP/1.1 500 Internal Server Error\"\n",
      "2025-10-27 21:19:45,645 - DEBUG - receive_response_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:19:45,646 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:19:45,647 - DEBUG - response_closed.started\n",
      "2025-10-27 21:19:45,647 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:19:45,649 - DEBUG - close.started\n",
      "2025-10-27 21:19:45,649 - DEBUG - close.complete\n",
      "2025-10-27 21:19:45,651 - INFO - Task run failed with exception: Exception() - Retry 2/4 will start 1 second(s) from now\n",
      "2025-10-27 21:19:46,675 - DEBUG - connect_tcp.started host='f3-vyx5c2hfpq-ue.a.run.app' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2025-10-27 21:19:46,689 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11384c650>\n",
      "2025-10-27 21:19:46,690 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1138fd650> server_hostname='f3-vyx5c2hfpq-ue.a.run.app' timeout=5.0\n",
      "2025-10-27 21:19:46,727 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11384f080>\n",
      "2025-10-27 21:19:46,728 - DEBUG - send_request_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:19:46,729 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:19:46,730 - DEBUG - send_request_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:19:46,730 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:19:46,731 - DEBUG - receive_response_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:19:48,344 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'content-type', b'text/html; charset=utf-8'), (b'x-cloud-trace-context', b'f54a11cafef680afbea64cdfc5ea1deb'), (b'date', b'Tue, 28 Oct 2025 03:19:48 GMT'), (b'server', b'Google Frontend'), (b'Content-Length', b'74'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000')])\n",
      "2025-10-27 21:19:48,345 - INFO - HTTP Request: GET https://f3-vyx5c2hfpq-ue.a.run.app/ \"HTTP/1.1 200 OK\"\n",
      "2025-10-27 21:19:48,346 - DEBUG - receive_response_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:19:48,347 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:19:48,348 - DEBUG - response_closed.started\n",
      "2025-10-27 21:19:48,349 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:19:48,350 - DEBUG - close.started\n",
      "2025-10-27 21:19:48,351 - DEBUG - close.complete\n",
      "2025-10-27 21:19:48,352 - INFO - Julius Ceasar, Henri II, Charles XI, and Napoleon were all afraid of cats.\n",
      "2025-10-27 21:19:48,357 - INFO - Finished in state Completed()\n",
      "2025-10-27 21:19:48,365 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:19:48,366 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:19:48,366 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:19:48,368 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:19:48,369 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:19:48,386 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 201, b'Created', [(b'date', b'Tue, 28 Oct 2025 03:19:48 GMT'), (b'server', b'uvicorn'), (b'content-length', b'412'), (b'content-type', b'application/json'), (b'vary', b'Accept-Encoding'), (b'content-encoding', b'gzip')])\n",
      "2025-10-27 21:19:48,387 - INFO - HTTP Request: POST http://127.0.0.1:4200/api/flow_runs/0260d32e-24a2-4bc0-8650-714e29321b2c/set_state \"HTTP/1.1 201 Created\"\n",
      "2025-10-27 21:19:48,388 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:19:48,390 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:19:48,391 - DEBUG - response_closed.started\n",
      "2025-10-27 21:19:48,391 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:19:48,393 - INFO - Finished in state Completed()\n",
      "2025-10-27 21:19:48,395 - DEBUG - close.started\n",
      "2025-10-27 21:19:48,395 - DEBUG - close.complete\n"
     ]
    }
   ],
   "source": [
    "fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe2a5180d8f6bc9",
   "metadata": {},
   "source": [
    "Ahora veamos el concepto de `subflows`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e82f34f9a0f83186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect import flow\n",
    "\n",
    "\n",
    "@flow(name=\"Cat fact\")\n",
    "def fetch_cat_fact():\n",
    "    \"\"\"A flow that gets a cat fact\"\"\"\n",
    "    return httpx.get(\"https://catfact.ninja/fact?max_length=140\").json()[\"fact\"]\n",
    "\n",
    "\n",
    "@flow(name=\"Dog fact\")\n",
    "def fetch_dog_fact():\n",
    "    \"\"\"A flow that gets a dog fact\"\"\"\n",
    "    return httpx.get(\n",
    "        \"https://dogapi.dog/api/v2/facts\",\n",
    "        headers={\"accept\": \"application/json\"},\n",
    "    ).json()[\"data\"][0][\"attributes\"][\"body\"]\n",
    "\n",
    "\n",
    "@flow(name=\"Animals fact\", log_prints=True)\n",
    "def animal_facts():\n",
    "    cat_fact = fetch_cat_fact()\n",
    "    dog_fact = fetch_dog_fact()\n",
    "    print(f\"üê±: {cat_fact} \\nüê∂: {dog_fact}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aa2d43e134d6635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-27 21:20:44,676 - DEBUG - connect_tcp.started host='127.0.0.1' port=4200 local_address=None timeout=60.0 socket_options=None\n",
      "2025-10-27 21:20:44,677 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1138b7c20>\n",
      "2025-10-27 21:20:44,677 - DEBUG - send_request_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:44,678 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:20:44,678 - DEBUG - send_request_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:44,679 - DEBUG - send_request_body.complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-27 21:20:44,680 - DEBUG - receive_response_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:44,681 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Tue, 28 Oct 2025 03:20:43 GMT'), (b'server', b'uvicorn'), (b'content-length', b'8'), (b'content-type', b'application/json')])\n",
      "2025-10-27 21:20:44,682 - INFO - HTTP Request: GET http://127.0.0.1:4200/api/admin/version \"HTTP/1.1 200 OK\"\n",
      "2025-10-27 21:20:44,683 - DEBUG - receive_response_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:44,684 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:20:44,685 - DEBUG - response_closed.started\n",
      "2025-10-27 21:20:44,685 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:20:44,687 - DEBUG - send_request_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:44,689 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:20:44,690 - DEBUG - send_request_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:44,690 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:20:44,691 - DEBUG - receive_response_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:44,693 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 422, b'Unprocessable Entity', [(b'date', b'Tue, 28 Oct 2025 03:20:43 GMT'), (b'server', b'uvicorn'), (b'content-length', b'41'), (b'content-type', b'application/json')])\n",
      "2025-10-27 21:20:44,693 - INFO - HTTP Request: GET http://127.0.0.1:4200/api/csrf-token?client=747845b6-176d-4de7-94bc-6625bf861c37 \"HTTP/1.1 422 Unprocessable Entity\"\n",
      "2025-10-27 21:20:44,694 - DEBUG - receive_response_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:44,695 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:20:44,697 - DEBUG - response_closed.started\n",
      "2025-10-27 21:20:44,699 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:20:44,702 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:44,703 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:20:44,704 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:44,705 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:20:44,705 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:44,713 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 201, b'Created', [(b'date', b'Tue, 28 Oct 2025 03:20:43 GMT'), (b'server', b'uvicorn'), (b'content-length', b'169'), (b'content-type', b'application/json')])\n",
      "2025-10-27 21:20:44,714 - INFO - HTTP Request: POST http://127.0.0.1:4200/api/flows/ \"HTTP/1.1 201 Created\"\n",
      "2025-10-27 21:20:44,715 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:44,715 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:20:44,716 - DEBUG - response_closed.started\n",
      "2025-10-27 21:20:44,717 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:20:44,719 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:44,720 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:20:44,720 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:44,722 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:20:44,723 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:44,740 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 201, b'Created', [(b'date', b'Tue, 28 Oct 2025 03:20:43 GMT'), (b'server', b'uvicorn'), (b'content-length', b'702'), (b'content-type', b'application/json'), (b'vary', b'Accept-Encoding'), (b'content-encoding', b'gzip')])\n",
      "2025-10-27 21:20:44,741 - INFO - HTTP Request: POST http://127.0.0.1:4200/api/flow_runs/ \"HTTP/1.1 201 Created\"\n",
      "2025-10-27 21:20:44,742 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:44,743 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:20:44,744 - DEBUG - response_closed.started\n",
      "2025-10-27 21:20:44,744 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:20:44,809 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:44,811 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:20:44,812 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:44,814 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:20:44,816 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:44,846 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 201, b'Created', [(b'date', b'Tue, 28 Oct 2025 03:20:44 GMT'), (b'server', b'uvicorn'), (b'content-length', b'409'), (b'content-type', b'application/json'), (b'vary', b'Accept-Encoding'), (b'content-encoding', b'gzip')])\n",
      "2025-10-27 21:20:44,847 - INFO - HTTP Request: POST http://127.0.0.1:4200/api/flow_runs/0ac5d5cc-16a1-4702-8030-c307a80e9f59/set_state \"HTTP/1.1 201 Created\"\n",
      "2025-10-27 21:20:44,847 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:44,848 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:20:44,849 - DEBUG - response_closed.started\n",
      "2025-10-27 21:20:44,850 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:20:44,851 - DEBUG - send_request_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:44,852 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:20:44,853 - DEBUG - send_request_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:44,854 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:20:44,855 - DEBUG - receive_response_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:44,861 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Tue, 28 Oct 2025 03:20:44 GMT'), (b'server', b'uvicorn'), (b'content-length', b'741'), (b'content-type', b'application/json'), (b'vary', b'Accept-Encoding'), (b'content-encoding', b'gzip')])\n",
      "2025-10-27 21:20:44,862 - INFO - HTTP Request: GET http://127.0.0.1:4200/api/flow_runs/0ac5d5cc-16a1-4702-8030-c307a80e9f59 \"HTTP/1.1 200 OK\"\n",
      "2025-10-27 21:20:44,862 - DEBUG - receive_response_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:44,863 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:20:44,864 - DEBUG - response_closed.started\n",
      "2025-10-27 21:20:44,865 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:20:44,868 - INFO - Beginning flow run 'overjoyed-grasshopper' for flow 'Animals fact'\n",
      "2025-10-27 21:20:44,869 - INFO - View at http://127.0.0.1:4200/runs/flow-run/0ac5d5cc-16a1-4702-8030-c307a80e9f59\n",
      "2025-10-27 21:20:44,893 - DEBUG - connect_tcp.started host='127.0.0.1' port=4200 local_address=None timeout=60.0 socket_options=None\n",
      "2025-10-27 21:20:44,895 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1138b6de0>\n",
      "2025-10-27 21:20:44,896 - DEBUG - send_request_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:44,897 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:20:44,898 - DEBUG - send_request_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:44,898 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:20:44,899 - DEBUG - receive_response_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:44,900 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 422, b'Unprocessable Entity', [(b'date', b'Tue, 28 Oct 2025 03:20:44 GMT'), (b'server', b'uvicorn'), (b'content-length', b'41'), (b'content-type', b'application/json')])\n",
      "2025-10-27 21:20:44,901 - INFO - HTTP Request: GET http://127.0.0.1:4200/api/csrf-token?client=e16b4dbe-a13a-4df2-9e9b-16d8f07741cb \"HTTP/1.1 422 Unprocessable Entity\"\n",
      "2025-10-27 21:20:44,901 - DEBUG - receive_response_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:44,902 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:20:44,903 - DEBUG - response_closed.started\n",
      "2025-10-27 21:20:44,903 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:20:44,905 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:44,906 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:20:44,907 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:44,908 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:20:44,908 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:44,931 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 201, b'Created', [(b'date', b'Tue, 28 Oct 2025 03:20:44 GMT'), (b'server', b'uvicorn'), (b'content-length', b'661'), (b'content-type', b'application/json'), (b'vary', b'Accept-Encoding'), (b'content-encoding', b'gzip')])\n",
      "2025-10-27 21:20:44,932 - INFO - HTTP Request: POST http://127.0.0.1:4200/api/task_runs/ \"HTTP/1.1 201 Created\"\n",
      "2025-10-27 21:20:44,932 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:44,933 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:20:44,934 - DEBUG - response_closed.started\n",
      "2025-10-27 21:20:44,935 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:20:44,937 - DEBUG - close.started\n",
      "2025-10-27 21:20:44,938 - DEBUG - close.complete\n",
      "2025-10-27 21:20:44,941 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:44,942 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:20:44,943 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:44,944 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:20:44,945 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:44,950 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 201, b'Created', [(b'date', b'Tue, 28 Oct 2025 03:20:44 GMT'), (b'server', b'uvicorn'), (b'content-length', b'165'), (b'content-type', b'application/json')])\n",
      "2025-10-27 21:20:44,951 - INFO - HTTP Request: POST http://127.0.0.1:4200/api/flows/ \"HTTP/1.1 201 Created\"\n",
      "2025-10-27 21:20:44,951 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:44,953 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:20:44,953 - DEBUG - response_closed.started\n",
      "2025-10-27 21:20:44,954 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:20:44,956 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:44,957 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:20:44,957 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:44,959 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:20:44,960 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:44,989 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 201, b'Created', [(b'date', b'Tue, 28 Oct 2025 03:20:44 GMT'), (b'server', b'uvicorn'), (b'content-length', b'723'), (b'content-type', b'application/json'), (b'vary', b'Accept-Encoding'), (b'content-encoding', b'gzip')])\n",
      "2025-10-27 21:20:44,990 - INFO - HTTP Request: POST http://127.0.0.1:4200/api/flow_runs/ \"HTTP/1.1 201 Created\"\n",
      "2025-10-27 21:20:44,991 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:44,992 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:20:44,992 - DEBUG - response_closed.started\n",
      "2025-10-27 21:20:44,993 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:20:45,001 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:45,002 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:20:45,003 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:45,004 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:20:45,005 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:45,028 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 201, b'Created', [(b'date', b'Tue, 28 Oct 2025 03:20:44 GMT'), (b'server', b'uvicorn'), (b'content-length', b'435'), (b'content-type', b'application/json'), (b'vary', b'Accept-Encoding'), (b'content-encoding', b'gzip')])\n",
      "2025-10-27 21:20:45,029 - INFO - HTTP Request: POST http://127.0.0.1:4200/api/flow_runs/c1384188-636a-4960-8d9b-e56128f4c35a/set_state \"HTTP/1.1 201 Created\"\n",
      "2025-10-27 21:20:45,030 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:45,031 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:20:45,032 - DEBUG - response_closed.started\n",
      "2025-10-27 21:20:45,033 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:20:45,036 - DEBUG - send_request_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:45,037 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:20:45,038 - DEBUG - send_request_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:45,039 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:20:45,041 - DEBUG - receive_response_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:45,048 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Tue, 28 Oct 2025 03:20:44 GMT'), (b'server', b'uvicorn'), (b'content-length', b'765'), (b'content-type', b'application/json'), (b'vary', b'Accept-Encoding'), (b'content-encoding', b'gzip')])\n",
      "2025-10-27 21:20:45,050 - INFO - HTTP Request: GET http://127.0.0.1:4200/api/flow_runs/c1384188-636a-4960-8d9b-e56128f4c35a \"HTTP/1.1 200 OK\"\n",
      "2025-10-27 21:20:45,051 - DEBUG - receive_response_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:45,053 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:20:45,055 - DEBUG - response_closed.started\n",
      "2025-10-27 21:20:45,056 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:20:45,059 - INFO - Beginning subflow run 'pastel-grebe' for flow 'Cat fact'\n",
      "2025-10-27 21:20:45,060 - INFO - View at http://127.0.0.1:4200/runs/flow-run/c1384188-636a-4960-8d9b-e56128f4c35a\n",
      "2025-10-27 21:20:45,079 - DEBUG - connect_tcp.started host='catfact.ninja' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2025-10-27 21:20:45,342 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11384fe00>\n",
      "2025-10-27 21:20:45,343 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x113913850> server_hostname='catfact.ninja' timeout=5.0\n",
      "2025-10-27 21:20:45,436 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x113827560>\n",
      "2025-10-27 21:20:45,437 - DEBUG - send_request_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:45,438 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:20:45,439 - DEBUG - send_request_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:45,440 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:20:45,441 - DEBUG - receive_response_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:45,558 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 28 Oct 2025 03:20:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Server', b'cloudflare'), (b'Cache-Control', b'no-cache, private'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-remaining', b'58'), (b'access-control-allow-origin', b'*'), (b'x-frame-options', b'SAMEORIGIN'), (b'x-xss-protection', b'1; mode=block'), (b'x-content-type-options', b'nosniff'), (b'Nel', b'{\"report_to\":\"cf-nel\",\"success_fraction\":0.0,\"max_age\":604800}'), (b'cf-cache-status', b'DYNAMIC'), (b'Report-To', b'{\"group\":\"cf-nel\",\"max_age\":604800,\"endpoints\":[{\"url\":\"https://a.nel.cloudflare.com/report/v4?s=0RmUn7JV0Lq%2BVQV4KR01K53F4Inw1oa5QTsJKNc3eRn1dbH5P9jQS7iar22zXhcmbva88DAt%2B6wYItk3wXkti7zOizMax5X%2F1XSWyVk%3D\"}]}'), (b'Content-Encoding', b'gzip'), (b'Set-Cookie', b'XSRF-TOKEN=eyJpdiI6InlDMEl6U1puK0lNVFZZL2RBd2VyeHc9PSIsInZhbHVlIjoiVTY2aXpTVWNlTXJCS2ZiWTV4SVRlVkxxSkxJSlpKS013UDZ0M09mWnRkOGtxVGU0bjhMWVdMaXZZZ00zcFpUREZmWlJ5czZ1SzlpL2svNUNhN3lGWUlPQTgvUUlpcHdnRTQ1cXB5dkRwUXorRlk0a2p0OUU1N0pDR3MzL25ZMEoiLCJtYWMiOiIxNTc2MjUzMTJjZDYyYjIyMjcyZTRiNmEzMDE1N2QzZjFjMWYyNjEwYWM0Yzk2MTQ2NTA0MGVkOTg5NmJmNzcwIiwidGFnIjoiIn0%3D; SameSite=Lax; Secure; Path=/; Max-Age=7200; Expires=Tue, 28 Oct 2025 05:20:45 GMT'), (b'Set-Cookie', b'catfacts_session=eyJpdiI6InRuNzIxOU1Gb3dKRFNOaUNWbUhPa0E9PSIsInZhbHVlIjoiQUdsaWlQa0ZjaHFUdlZwZnZZK0h4TmRBeVUxK1g1a1BmQ1M1b3lncldQTlJHT0tIcWtscTZiWmFGRS9uQmNxV3VSK2lmcW51Qk1SUGRPRjRCcWJ4aERkT2lobFJRVnM3RjBLN0ZaS3J6dkJMTEYyTnNEblpUSzhQWlVpbWxNVkYiLCJtYWMiOiIzZTMwYThhZmIzOGExNDJiOTFjZTI5ZWQ1MjY1NWRhMWJjMDM2OGVlNzU5MzViM2UwZDkwYjY1Y2UyYzljMjFiIiwidGFnIjoiIn0%3D; HttpOnly; SameSite=Lax; Secure; Path=/; Max-Age=7200; Expires=Tue, 28 Oct 2025 05:20:45 GMT'), (b'Set-Cookie', b'l0rf0UES20gnnw5YwweXTmqZnxq3xyX7QJGKHN8x=eyJpdiI6IlVRNU4wSURRK2tVZkJrdEVrWFp5dVE9PSIsInZhbHVlIjoiMjhBUEhEckxJbG9MdnEyamdXMHlybXZxaVkxUjFSNlpodEpTUjZHdE5hUnpDUTROT3RkaTBuQnZGZXJBbThmOFRXNzVaMGhoK3ZEK3ByMjBHU2ZBQThzWFkzN3VRZDl0cXlmU0d6L1NHZmg2VFVJaTRmMThaWk9DNFJPVlNmcEhGb241STd6b1RQS0pGSnJFV3JrL3pkTnJLZ2lwdUVrL0N6TEFpQjNrd2kraldFb2V3SHZYS0J3RGxYZ1l3cFVyc01jMElKYlE4TVB5SmQ3RG9ZeUtEVE4ydGczQmdjeG42VGJid2FZTE9KRkd1ZDlPaU9uZ0JGRVc2YXVKYWNQVFdUeDRTNDdDV2IyVHVqSEpFbU01Z3NsQlNBUGhlRkNXRmtJWWgrYk5mYW1IWndhWGJ0U05WK283WlVWQ0JkWG16NVU4K1FZa3JKbXk1N3d2NUVXdDdEWUF6dHBaOC81ZURWc2F2RTl5eUJBdVlEbEhkekZacldQbkZXK1VsSkhvWGhsTkpyVjNqc1c0VGt4aTdSem9PQT09IiwibWFjIjoiNmI5NzBjZjFlZWVhODg3YzBhNDE4OTg5ZWU1ZjFmYjE5ZDFlZjhkN2Y5NGI4M2NmNDE3ZmQxZjNmNDZjMjAwYyIsInRhZyI6IiJ9; HttpOnly; SameSite=Lax; Secure; Path=/; Max-Age=7200; Expires=Tue, 28 Oct 2025 05:20:45 GMT'), (b'CF-RAY', b'99574c95ba8b38fb-IAD'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-10-27 21:20:45,560 - INFO - HTTP Request: GET https://catfact.ninja/fact?max_length=140 \"HTTP/1.1 200 OK\"\n",
      "2025-10-27 21:20:45,560 - DEBUG - receive_response_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:45,562 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:20:45,562 - DEBUG - response_closed.started\n",
      "2025-10-27 21:20:45,563 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:20:45,564 - DEBUG - close.started\n",
      "2025-10-27 21:20:45,565 - DEBUG - close.complete\n",
      "2025-10-27 21:20:45,570 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:45,570 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:20:45,571 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:45,572 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:20:45,572 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:45,614 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 201, b'Created', [(b'date', b'Tue, 28 Oct 2025 03:20:44 GMT'), (b'server', b'uvicorn'), (b'content-length', b'436'), (b'content-type', b'application/json'), (b'vary', b'Accept-Encoding'), (b'content-encoding', b'gzip')])\n",
      "2025-10-27 21:20:45,615 - INFO - HTTP Request: POST http://127.0.0.1:4200/api/flow_runs/c1384188-636a-4960-8d9b-e56128f4c35a/set_state \"HTTP/1.1 201 Created\"\n",
      "2025-10-27 21:20:45,615 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:45,616 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:20:45,617 - DEBUG - response_closed.started\n",
      "2025-10-27 21:20:45,617 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:20:45,619 - INFO - Finished in state Completed()\n",
      "2025-10-27 21:20:45,638 - DEBUG - connect_tcp.started host='127.0.0.1' port=4200 local_address=None timeout=60.0 socket_options=None\n",
      "2025-10-27 21:20:45,640 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x112742ea0>\n",
      "2025-10-27 21:20:45,641 - DEBUG - send_request_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:45,642 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:20:45,643 - DEBUG - send_request_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:45,643 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:20:45,645 - DEBUG - receive_response_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:45,647 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 422, b'Unprocessable Entity', [(b'date', b'Tue, 28 Oct 2025 03:20:44 GMT'), (b'server', b'uvicorn'), (b'content-length', b'41'), (b'content-type', b'application/json')])\n",
      "2025-10-27 21:20:45,648 - INFO - HTTP Request: GET http://127.0.0.1:4200/api/csrf-token?client=504ba903-8c7d-4951-b202-2d6be5a0f0aa \"HTTP/1.1 422 Unprocessable Entity\"\n",
      "2025-10-27 21:20:45,648 - DEBUG - receive_response_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:45,649 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:20:45,650 - DEBUG - response_closed.started\n",
      "2025-10-27 21:20:45,651 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:20:45,654 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:45,655 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:20:45,656 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:45,657 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:20:45,658 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:45,678 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 201, b'Created', [(b'date', b'Tue, 28 Oct 2025 03:20:44 GMT'), (b'server', b'uvicorn'), (b'content-length', b'659'), (b'content-type', b'application/json'), (b'vary', b'Accept-Encoding'), (b'content-encoding', b'gzip')])\n",
      "2025-10-27 21:20:45,680 - INFO - HTTP Request: POST http://127.0.0.1:4200/api/task_runs/ \"HTTP/1.1 201 Created\"\n",
      "2025-10-27 21:20:45,681 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:45,683 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:20:45,683 - DEBUG - response_closed.started\n",
      "2025-10-27 21:20:45,684 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:20:45,686 - DEBUG - close.started\n",
      "2025-10-27 21:20:45,687 - DEBUG - close.complete\n",
      "2025-10-27 21:20:45,689 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:45,690 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:20:45,691 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:45,692 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:20:45,693 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:45,700 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 201, b'Created', [(b'date', b'Tue, 28 Oct 2025 03:20:44 GMT'), (b'server', b'uvicorn'), (b'content-length', b'165'), (b'content-type', b'application/json')])\n",
      "2025-10-27 21:20:45,701 - INFO - HTTP Request: POST http://127.0.0.1:4200/api/flows/ \"HTTP/1.1 201 Created\"\n",
      "2025-10-27 21:20:45,702 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:45,703 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:20:45,704 - DEBUG - response_closed.started\n",
      "2025-10-27 21:20:45,705 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:20:45,707 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:45,708 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:20:45,708 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:45,709 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:20:45,710 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:45,749 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 201, b'Created', [(b'date', b'Tue, 28 Oct 2025 03:20:44 GMT'), (b'server', b'uvicorn'), (b'content-length', b'721'), (b'content-type', b'application/json'), (b'vary', b'Accept-Encoding'), (b'content-encoding', b'gzip')])\n",
      "2025-10-27 21:20:45,749 - INFO - HTTP Request: POST http://127.0.0.1:4200/api/flow_runs/ \"HTTP/1.1 201 Created\"\n",
      "2025-10-27 21:20:45,750 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:45,752 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:20:45,753 - DEBUG - response_closed.started\n",
      "2025-10-27 21:20:45,753 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:20:45,763 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:45,764 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:20:45,765 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:45,766 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:20:45,767 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:45,792 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 201, b'Created', [(b'date', b'Tue, 28 Oct 2025 03:20:44 GMT'), (b'server', b'uvicorn'), (b'content-length', b'435'), (b'content-type', b'application/json'), (b'vary', b'Accept-Encoding'), (b'content-encoding', b'gzip')])\n",
      "2025-10-27 21:20:45,793 - INFO - HTTP Request: POST http://127.0.0.1:4200/api/flow_runs/8b9d963b-3962-466a-8b94-980cbec6f5d9/set_state \"HTTP/1.1 201 Created\"\n",
      "2025-10-27 21:20:45,794 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:45,795 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:20:45,796 - DEBUG - response_closed.started\n",
      "2025-10-27 21:20:45,797 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:20:45,799 - DEBUG - send_request_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:45,800 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:20:45,801 - DEBUG - send_request_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:45,802 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:20:45,803 - DEBUG - receive_response_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:45,813 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Tue, 28 Oct 2025 03:20:44 GMT'), (b'server', b'uvicorn'), (b'content-length', b'762'), (b'content-type', b'application/json'), (b'vary', b'Accept-Encoding'), (b'content-encoding', b'gzip')])\n",
      "2025-10-27 21:20:45,814 - INFO - HTTP Request: GET http://127.0.0.1:4200/api/flow_runs/8b9d963b-3962-466a-8b94-980cbec6f5d9 \"HTTP/1.1 200 OK\"\n",
      "2025-10-27 21:20:45,815 - DEBUG - receive_response_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:45,817 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:20:45,818 - DEBUG - response_closed.started\n",
      "2025-10-27 21:20:45,819 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:20:45,823 - INFO - Beginning subflow run 'crystal-koala' for flow 'Dog fact'\n",
      "2025-10-27 21:20:45,825 - INFO - View at http://127.0.0.1:4200/runs/flow-run/8b9d963b-3962-466a-8b94-980cbec6f5d9\n",
      "2025-10-27 21:20:45,844 - DEBUG - connect_tcp.started host='dogapi.dog' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2025-10-27 21:20:46,208 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x113886270>\n",
      "2025-10-27 21:20:46,209 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x113919550> server_hostname='dogapi.dog' timeout=5.0\n",
      "2025-10-27 21:20:46,605 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x113887470>\n",
      "2025-10-27 21:20:46,606 - DEBUG - send_request_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:46,608 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:20:46,609 - DEBUG - send_request_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:46,610 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:20:46,611 - DEBUG - receive_response_headers.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:46,824 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'max-age=0, private, must-revalidate'), (b'Content-Length', b'182'), (b'Content-Type', b'application/vnd.api+json; charset=utf-8'), (b'Etag', b'W/\"76e7667b2c4496f84bf0834736b40b40\"'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Vary', b'Accept, Origin'), (b'X-Content-Type-Options', b'nosniff'), (b'X-Download-Options', b'noopen'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Permitted-Cross-Domain-Policies', b'none'), (b'X-Request-Id', b'cbdce59b-1cae-4e8d-beb0-dee771eca1df'), (b'X-Runtime', b'0.028349'), (b'X-Xss-Protection', b'0'), (b'Date', b'Tue, 28 Oct 2025 03:20:46 GMT')])\n",
      "2025-10-27 21:20:46,825 - INFO - HTTP Request: GET https://dogapi.dog/api/v2/facts \"HTTP/1.1 200 OK\"\n",
      "2025-10-27 21:20:46,827 - DEBUG - receive_response_body.started request=<Request [b'GET']>\n",
      "2025-10-27 21:20:46,828 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:20:46,828 - DEBUG - response_closed.started\n",
      "2025-10-27 21:20:46,829 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:20:46,830 - DEBUG - close.started\n",
      "2025-10-27 21:20:46,831 - DEBUG - close.complete\n",
      "2025-10-27 21:20:46,835 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:46,836 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:20:46,837 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:46,838 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:20:46,838 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:46,865 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 201, b'Created', [(b'date', b'Tue, 28 Oct 2025 03:20:46 GMT'), (b'server', b'uvicorn'), (b'content-length', b'434'), (b'content-type', b'application/json'), (b'vary', b'Accept-Encoding'), (b'content-encoding', b'gzip')])\n",
      "2025-10-27 21:20:46,866 - INFO - HTTP Request: POST http://127.0.0.1:4200/api/flow_runs/8b9d963b-3962-466a-8b94-980cbec6f5d9/set_state \"HTTP/1.1 201 Created\"\n",
      "2025-10-27 21:20:46,867 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:46,868 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:20:46,869 - DEBUG - response_closed.started\n",
      "2025-10-27 21:20:46,869 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:20:46,871 - INFO - Finished in state Completed()\n",
      "2025-10-27 21:20:46,873 - INFO - üê±: A cat's normal temperature varies around 101 degrees Fahrenheit. \n",
      "üê∂: The shortest living dog was a Chihuahua named Milly, who measured only 3.8 inches tall.\n",
      "2025-10-27 21:20:46,879 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:46,880 - DEBUG - send_request_headers.complete\n",
      "2025-10-27 21:20:46,880 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:46,881 - DEBUG - send_request_body.complete\n",
      "2025-10-27 21:20:46,882 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:46,894 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 201, b'Created', [(b'date', b'Tue, 28 Oct 2025 03:20:46 GMT'), (b'server', b'uvicorn'), (b'content-length', b'412'), (b'content-type', b'application/json'), (b'vary', b'Accept-Encoding'), (b'content-encoding', b'gzip')])\n",
      "2025-10-27 21:20:46,895 - INFO - HTTP Request: POST http://127.0.0.1:4200/api/flow_runs/0ac5d5cc-16a1-4702-8030-c307a80e9f59/set_state \"HTTP/1.1 201 Created\"\n",
      "2025-10-27 21:20:46,896 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-10-27 21:20:46,898 - DEBUG - receive_response_body.complete\n",
      "2025-10-27 21:20:46,898 - DEBUG - response_closed.started\n",
      "2025-10-27 21:20:46,899 - DEBUG - response_closed.complete\n",
      "2025-10-27 21:20:46,900 - INFO - Finished in state Completed()\n",
      "2025-10-27 21:20:46,902 - DEBUG - close.started\n",
      "2025-10-27 21:20:46,903 - DEBUG - close.complete\n"
     ]
    }
   ],
   "source": [
    "animal_facts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982db0e9319221ee",
   "metadata": {},
   "source": [
    "Ahora vamos a hacerlo para nuestro pipeline de entrenamiento en nuestro proyecto `nyc-taxi-time-prediction`\n",
    "\n",
    "- Vamos a crear una nueva rama `feat/training_orchestration`. \n",
    "- Vamos a crear un nuevo directorio `training pipeline`\n",
    "- crear un archivo llamado `02-train_pipeline_prefect.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b026cb8548f546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import optuna\n",
    "import pathlib\n",
    "import pickle\n",
    "import mlflow\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from dotenv import load_dotenv\n",
    "from optuna.samplers import TPESampler\n",
    "from mlflow.models.signature import infer_signature\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from prefect import flow, task\n",
    "\n",
    "@task(name=\"Read Data\")\n",
    "def read_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Read data into DataFrame\"\"\"\n",
    "    df = pd.read_parquet(file_path)\n",
    "\n",
    "    df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "    df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "\n",
    "    df[\"duration\"] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = [\"PULocationID\", \"DOLocationID\"]\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    return df\n",
    "\n",
    "@task(name=\"Add Features\")\n",
    "def add_features(df_train: pd.DataFrame, df_val: pd.DataFrame):\n",
    "    \"\"\"Add features to the model\"\"\"\n",
    "    df_train[\"PU_DO\"] = df_train[\"PULocationID\"] + \"_\" + df_train[\"DOLocationID\"]\n",
    "    df_val[\"PU_DO\"] = df_val[\"PULocationID\"] + \"_\" + df_val[\"DOLocationID\"]\n",
    "\n",
    "    categorical = [\"PU_DO\"]  #'PULocationID', 'DOLocationID']\n",
    "    numerical = [\"trip_distance\"]\n",
    "\n",
    "    dv = DictVectorizer()\n",
    "\n",
    "    train_dicts = df_train[categorical + numerical].to_dict(orient=\"records\")\n",
    "    X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "    val_dicts = df_val[categorical + numerical].to_dict(orient=\"records\")\n",
    "    X_val = dv.transform(val_dicts)\n",
    "\n",
    "    y_train = df_train[\"duration\"].values\n",
    "    y_val = df_val[\"duration\"].values\n",
    "    return X_train, X_val, y_train, y_val, dv\n",
    "\n",
    "@task(name=\"Hyperparameter Tunning\")\n",
    "def hyper_parameter_tunning(X_train, X_val, y_train, y_val, dv):\n",
    "    \n",
    "    mlflow.xgboost.autolog()\n",
    "    \n",
    "    training_dataset = mlflow.data.from_numpy(X_train.data, targets=y_train, name=\"green_tripdata_2024-01\")\n",
    "    \n",
    "    validation_dataset = mlflow.data.from_numpy(X_val.data, targets=y_val, name=\"green_tripdata_2024-02\")\n",
    "    \n",
    "    train = xgb.DMatrix(X_train, label=y_train)\n",
    "    \n",
    "    valid = xgb.DMatrix(X_val, label=y_val)\n",
    "    \n",
    "    # ------------------------------------------------------------\n",
    "    # Definir la funci√≥n objetivo para Optuna\n",
    "    #    - Recibe un `trial`, que se usa para proponer hiperpar√°metros.\n",
    "    #    - Entrena un modelo con esos hiperpar√°metros.\n",
    "    #    - Calcula la m√©trica de validaci√≥n (RMSE) y la retorna (Optuna la minimizar√°).\n",
    "    #    - Abrimos un run anidado de MLflow para registrar cada trial.\n",
    "    # ------------------------------------------------------------\n",
    "    def objective(trial: optuna.trial.Trial):\n",
    "        # Hiperpar√°metros MUESTREADOS por Optuna en CADA trial.\n",
    "        # Nota: usamos log=True para emular rangos log-uniformes (similar a loguniform).\n",
    "        params = {\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 4, 100),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", math.exp(-3), 1.0, log=True),\n",
    "            \"reg_alpha\": trial.suggest_float(\"reg_alpha\",   math.exp(-5), math.exp(-1), log=True),\n",
    "            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", math.exp(-6), math.exp(-1), log=True),\n",
    "            \"min_child_weight\": trial.suggest_float(\"min_child_weight\", math.exp(-1), math.exp(3), log=True),\n",
    "            \"objective\": \"reg:squarederror\",  \n",
    "            \"seed\": 42,                      \n",
    "        }\n",
    "\n",
    "        # Run anidado para dejar rastro de cada trial en MLflow\n",
    "        with mlflow.start_run(nested=True):\n",
    "            mlflow.set_tag(\"model_family\", \"xgboost\")  # etiqueta informativa\n",
    "            mlflow.log_params(params)                  # registra hiperpar√°metros del trial\n",
    "\n",
    "            # Entrenamiento con early stopping en el conjunto de validaci√≥n\n",
    "            booster = xgb.train(\n",
    "                params=params,\n",
    "                dtrain=train,\n",
    "                num_boost_round=100,\n",
    "                evals=[(valid, \"validation\")],\n",
    "                early_stopping_rounds=10,\n",
    "            )\n",
    "\n",
    "            # Predicci√≥n y m√©trica en validaci√≥n\n",
    "            y_pred = booster.predict(valid)\n",
    "            rmse = root_mean_squared_error(y_val, y_pred)\n",
    "\n",
    "            # Registrar la m√©trica principal\n",
    "            mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "            # La \"signature\" describe la estructura esperada de entrada y salida del modelo:\n",
    "            # incluye los nombres, tipos y forma (shape) de las variables de entrada y el tipo de salida.\n",
    "            # MLflow la usa para validar datos en inferencia y documentar el modelo en el Model Registry.\n",
    "            signature = infer_signature(X_val, y_pred)\n",
    "\n",
    "            # Guardar el modelo del trial como artefacto en MLflow.\n",
    "            mlflow.xgboost.log_model(\n",
    "                booster,\n",
    "                name=\"model\",\n",
    "                input_example=X_val[:5],\n",
    "                signature=signature\n",
    "            )\n",
    "\n",
    "        # Optuna minimiza el valor retornado\n",
    "        return rmse\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Crear el estudio de Optuna\n",
    "    #    - Usamos TPE (Tree-structured Parzen Estimator) como sampler.\n",
    "    #    - direction=\"minimize\" porque queremos minimizar el RMSE.\n",
    "    # ------------------------------------------------------------\n",
    "    sampler = TPESampler(seed=42)\n",
    "    study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Ejecutar la optimizaci√≥n (n_trials = n√∫mero de intentos)\n",
    "    #    - Cada trial ejecuta la funci√≥n objetivo con un set distinto de hiperpar√°metros.\n",
    "    #    - Abrimos un run \"padre\" para agrupar toda la b√∫squeda.\n",
    "    # ------------------------------------------------------------\n",
    "    with mlflow.start_run(run_name=\"XGBoost Hyperparameter Optimization (Optuna)\", nested=True):\n",
    "        study.optimize(objective, n_trials=3)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Recuperar y registrar los mejores hiperpar√°metros\n",
    "    # --------------------------------------------------------\n",
    "    best_params = study.best_params\n",
    "    # Asegurar tipos/campos fijos (por claridad y consistencia)\n",
    "    best_params[\"max_depth\"] = int(best_params[\"max_depth\"])\n",
    "    best_params[\"seed\"] = 42\n",
    "    best_params[\"objective\"] = \"reg:squarederror\"\n",
    "\n",
    "    return best_params\n",
    "\n",
    "@task(name=\"Train Best Model\")\n",
    "def train_best_model(X_train, X_val, y_train, y_val, dv, best_params) -> None:\n",
    "    \"\"\"train a model with best hyperparams and write everything out\"\"\"\n",
    "\n",
    "    with mlflow.start_run(run_name=\"Best model ever\"):\n",
    "        train = xgb.DMatrix(X_train, label=y_train)\n",
    "        valid = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "        mlflow.log_params(best_params)\n",
    "\n",
    "        # Etiquetas del run \"padre\" (metadatos del experimento)\n",
    "        mlflow.set_tags({\n",
    "            \"project\": \"NYC Taxi Time Prediction Project\",\n",
    "            \"optimizer_engine\": \"optuna\",\n",
    "            \"model_family\": \"xgboost\",\n",
    "            \"feature_set_version\": 1,\n",
    "        })\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # 7) Entrenar un modelo FINAL con los mejores hiperpar√°metros\n",
    "        #    (normalmente se har√≠a sobre train+val o con CV; aqu√≠ mantenemos el patr√≥n original)\n",
    "        # --------------------------------------------------------\n",
    "        booster = xgb.train(\n",
    "            params=best_params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=100,\n",
    "            evals=[(valid, \"validation\")],\n",
    "            early_stopping_rounds=10,\n",
    "        )\n",
    "\n",
    "        # Evaluar y registrar la m√©trica final en validaci√≥n\n",
    "        y_pred = booster.predict(valid)\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # 8) Guardar artefactos adicionales (p. ej. el preprocesador)\n",
    "        # --------------------------------------------------------\n",
    "        pathlib.Path(\"preprocessor\").mkdir(exist_ok=True)\n",
    "        with open(\"preprocessor/preprocessor.b\", \"wb\") as f_out:\n",
    "            pickle.dump(dv, f_out)\n",
    "\n",
    "        mlflow.log_artifact(\"preprocessor/preprocessor.b\", artifact_path=\"preprocessor\")\n",
    "\n",
    "        # La \"signature\" describe la estructura esperada de entrada y salida del modelo:\n",
    "        # incluye los nombres, tipos y forma (shape) de las variables de entrada y el tipo de salida.\n",
    "        # MLflow la usa para validar datos en inferencia y documentar el modelo en el Model Registry.\n",
    "        # Si X_val es la matriz dispersa (scipy.sparse) salida de DictVectorizer:\n",
    "        feature_names = dv.get_feature_names_out()\n",
    "        input_example = pd.DataFrame(X_val[:5].toarray(), columns=feature_names)\n",
    "\n",
    "        # Para que las longitudes coincidan, usa el mismo slice en y_pred\n",
    "        signature = infer_signature(input_example, y_val[:5])\n",
    "\n",
    "        # Guardar el modelo del trial como artefacto en MLflow.\n",
    "        mlflow.xgboost.log_model(\n",
    "            booster,\n",
    "            name=\"model\",\n",
    "            input_example=input_example,\n",
    "            signature=signature,\n",
    "        )\n",
    "    return None\n",
    "\n",
    "@flow(name=\"Main Flow\")\n",
    "def main_flow(year: int, month_train: str, month_val: str) -> None:\n",
    "    \"\"\"The main training pipeline\"\"\"\n",
    "    \n",
    "    train_path = f\"../data/green_tripdata_{year}-{month_train}.parquet\"\n",
    "    val_path = f\"../data/green_tripdata_{year}-{month_val}.parquet\"\n",
    "    \n",
    "    load_dotenv(override=True)  # Carga las variables del archivo .env\n",
    "    EXPERIMENT_NAME = \"/Users/<tu_correo>/nyc-taxi-experiment-prefect\"\n",
    "\n",
    "    mlflow.set_tracking_uri(\"databricks\")\n",
    "    experiment = mlflow.set_experiment(experiment_name=EXPERIMENT_NAME)\n",
    "\n",
    "    # Load\n",
    "    df_train = read_data(train_path)\n",
    "    df_val = read_data(val_path)\n",
    "\n",
    "    # Transform\n",
    "    X_train, X_val, y_train, y_val, dv = add_features(df_train, df_val)\n",
    "    \n",
    "    # Hyper-parameter Tunning\n",
    "    best_params = hyper_parameter_tunning(X_train, X_val, y_train, y_val, dv)\n",
    "    \n",
    "    # Train\n",
    "    train_best_model(X_train, X_val, y_train, y_val, dv, best_params)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_flow(year=2025, month_train=\"01\", month_val=\"02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432aa2c3",
   "metadata": {},
   "source": [
    "## Actividad en clase:\n",
    "### A los 5 primeros que logren terminar la siguiente actividad les subir√© el puntaje a 100 de la tarea con menor calificaci√≥n actualmente.\n",
    "\n",
    "1. Crear una nueva task para agregar el modelo con mejor m√©trica al `model registry`.\n",
    "2. El modelo debe tener como nombre `nyc-taxi-model-prefect` en el `model registry` para diferenciarlo del modelo que ya tenemos actualmente.\n",
    "3. El registro debe ser autom√°tico, puede hacer uso de la funci√≥n `mlflow.register_model` que ya saben utilizar de la tarea anterior.\n",
    "4. Si recuerdan, esa funci√≥n requiere un `run_uri`, el cual se conformaba algo como `f\"runs:/{run_id}/model\"`. Nosotros buscabamos manualmente el `run_id`, pero `mlflow` tiene manera de hacer una query y ordenar los resultados por m√©trica en orden ascendente y devolver dicho `run_id`.\n",
    "5. Busque dicha funci√≥n e implem√©ntela en la l√≥gica para que sea de manera autom√°tica la obtenci√≥n del `run_uri`. Use la documentaci√≥n oficial de `mlflow`, saber leer y usar la documentaci√≥n es una skill que como Data Scientist tambi√©n debe tener. PROHIBIDO EL USO DE CHATGPT.\n",
    "6. As√≠gnele a esa versi√≥n del modelo registrado, el alias de `@champion`.\n",
    "7. Corra el pipeline y verifique que se haya registrado el modelo en el `model registry`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cf6a75",
   "metadata": {},
   "source": [
    "## Tarea 6\n",
    "\n",
    "1. Terminar la actividad anterior.\n",
    "2. Crear un nuevo script llamado `train_challenger.py` dentro del directorio `training pipeline`\n",
    "3. Convertir la tarea 5 en un `flow` (en donde entren√≥ dos modelos, al mejor le asign√≥ el alias `@challenger` compar√≥ el desempe√±o con el `@champion`).\n",
    "4. El `flow` debe escoger qui√©n es el nuevo `@champion` y asignarle el alias respectivo.\n",
    "5. Recuerde definir las `task` que considere\n",
    "6. Recuerde que los nombres de los `flow` deben ser √∫nicos, que no interfiera con el `flow` del ejercicio anterior.\n",
    "7. Use el mismo nombre del experimeto del ejercicio anterior `nyc-taxi-experiment-prefect`\n",
    "8. Registre los modelos en el mismo `Model Registry` del ejercicio anterior `nyc-taxi-model-prefect`\n",
    "9. Cree un `PR` con los cambios hecho en esta branch hacia `main` y hacer el merge.\n",
    "\n",
    "## Fecha de entrega:\n",
    "Martes 4 de Noviembre antes de la clase: 19:55"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proyciendatos2025-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
