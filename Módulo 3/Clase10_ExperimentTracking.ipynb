{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c50db405b30e165",
   "metadata": {},
   "source": [
    "# Quiz Clase 8 y 9 sobre MLOps siguiente semana 14 de Octubre de 2025 en clase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6d2b4578bbb04",
   "metadata": {},
   "source": [
    "# Seguimiento de Experimentos\n",
    "https://neptune.ai/blog/ml-experiment-tracking\n",
    "\n",
    " <img style=\"display: block; margin: auto;\" src=\"./images/mlops-experiment-tracking-excalidraw.png\" width=\"1280\" height=\"50\">\n",
    " \n",
    "## 1. Motivaci√≥n\n",
    "\n",
    "Imaginemos que se est√° tratando de desarrollar la receta perfecta para las mejores galletas con chispas de chocolate. \n",
    "- Despu√©s del primer intento, se decide aumentar la cantidad de harina. \n",
    "- En otro momento, se agregan m√°s chispas de chocolate. \n",
    "- Luego, se prueba a√±adiendo nueces. \n",
    "- Al final, se habr√°n probado una docena de recetas, pero ¬øc√≥mo se sabr√≠a cu√°l fue la mejor?\n",
    "\n",
    "Seguramente se estar√≠a de acuerdo en que tomar notas durante este proceso ser√≠a una buena idea. Anotar los ingredientes y c√≥mo resultaron las galletas ayudar√≠a a saber qu√© funcion√≥ mejor.\n",
    "\n",
    "Ahora consideremos la siguiente historia:\n",
    "\n",
    "    ... Hasta ahora, todo se ha estado haciendo de manera manual y algo ad hoc.\n",
    "    \n",
    "    Algunas personas est√°n usando esto, otras personas est√°n usando aquello; est√° todo desorganizado.\n",
    "    \n",
    "    No tenemos nada estandarizado.\n",
    "    \n",
    "    Pero ejecutamos muchos proyectos, el equipo est√° creciendo y estamos escalando muy r√°pido.\n",
    "    \n",
    "    Por lo tanto, nos encontramos con muchos problemas. ¬øC√≥mo se entren√≥ el modelo? ¬øCon qu√© datos? ¬øQu√© par√°metros se usaron para las diferentes versiones? ¬øC√≥mo podemos reproducirlos?\n",
    "    \n",
    "    Sentimos la necesidad de controlar nuestros experimentos‚Ä¶\n",
    "\n",
    "La verdad es que, cuando se desarrollan modelos de Machine Learning (ML), se realizan muchos experimentos. \n",
    "\n",
    "Y esos experimentos pueden:\n",
    "\n",
    "+ Usar diferentes modelos y hiperpar√°metros.\n",
    "+ Emplear distintos datos de entrenamiento o evaluaci√≥n.\n",
    "+ Ejecutar diferentes c√≥digos (incluyendo ese peque√±o cambio que se quiso probar el otro d√≠a).\n",
    "+ Correr el mismo c√≥digo en un entorno diferente (sin saber qu√© versi√≥n de las librer√≠as estaba instalada).\n",
    "\n",
    "Como resultado, cada uno de estos experimentos puede producir m√©tricas de evaluaci√≥n completamente diferentes. Cada ajuste en los par√°metros o cambios en el algoritmo puede tener un gran impacto en el rendimiento del modelo, al igual que las variaciones en la receta afectan el sabor de las galletas.\n",
    "\n",
    "Mantener un seguimiento de toda esa informaci√≥n se vuelve realmente dif√≠cil muy r√°pidamente. Especialmente si se desea organizar y comparar muchos experimentos y sentirse seguro de haber seleccionado los mejores modelos para llevar a producci√≥n.\n",
    "\n",
    "Aqu√≠ es donde entra el seguimiento de experimentos. Llevar un registro detallado de los experimentos permite guardar informaci√≥n sobre qu√© cambios produjeron mejores resultados y cu√°les no, facilitando la identificaci√≥n del enfoque m√°s efectivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eabca25e87783e",
   "metadata": {},
   "source": [
    "## 2. Definiciones\n",
    "\n",
    "* **Seguimiento de Experimentos** en el contexto del aprendizaje autom√°tico se refiere al proceso de registrar y organizar sistem√°ticamente toda la informaci√≥n relevante sobre cada experimento realizado durante el desarrollo de modelos de ML. Un experimento de ML es un enfoque sistem√°tico para probar una hip√≥tesis, y su metadata relevante incluye los insumos y salidas del experimento.\n",
    "\n",
    "* **Experiment**:\n",
    "   - **Definici√≥n**: Un experimento es un grupo l√≥gico de ejecuciones (runs). Es un contenedor para rastrear diferentes versiones de modelos o configuraciones dentro de un proyecto de aprendizaje autom√°tico. Cada experimento puede contener varias ejecuciones con distintos par√°metros, algoritmos o conjuntos de datos, lo que facilita la comparaci√≥n entre versiones del modelo.\n",
    "   - **Ejemplo**: En un proyecto de clasificaci√≥n de im√°genes de gatos y perros, podr√≠as tener un experimento llamado \"Clasificador de Gatos y Perros\". En este experimento, probar√≠as diferentes modelos (`ResNet50`, `VGG16`, `MobileNet`) y ajustes de hiperpar√°metros, evaluando cu√°l ofrece el mejor rendimiento.\n",
    "\n",
    "* **Run**:\n",
    "   - **Definici√≥n**: Un run es la ejecuci√≥n individual de un modelo de entrenamiento dentro de un experimento. Cada run registra detalles como par√°metros (entradas), m√©tricas (salidas), y otros metadatos importantes. Un nuevo run es creado cada vez que se ejecuta un trabajo de entrenamiento, y se le asigna un ID √∫nico para su seguimiento.\n",
    "   - **Ejemplo**: Ejecutar un entrenamiento con `ResNet50` y una tasa de aprendizaje de 0.001 y un batch size de 32 se registrar√≠a como un _run_. Este run podr√≠a incluir:\n",
    "     - **Modelo:** ResNet50\n",
    "     - **Par√°metros:**\n",
    "       - `learning_rate = 0.001`\n",
    "       - `batch_size = 32`\n",
    "     - **M√©tricas:**\n",
    "       - `accuracy = 0.89`\n",
    "       - `loss = 0.35`\n",
    "     - **Artefactos:** El modelo entrenado, un gr√°fico de la matriz de confusi√≥n, y los logs del proceso de entrenamiento.\n",
    "\n",
    "* **Artifact**:\n",
    "   - **Definici√≥n**: Un artefacto se refiere a cualquier archivo o dato generado como parte de un experimento de ML. Esto puede incluir el modelo entrenado, resultados de evaluaci√≥n, gr√°ficos, archivos de predicci√≥n, o conjuntos de datos usados.\n",
    "   - **Ejemplo**: Despu√©s de un run, los artefactos generados podr√≠an incluir:\n",
    "     - El modelo entrenado (e.g., `model_resnet50_v1.pkl`).\n",
    "     - Un gr√°fico de las curvas de aprendizaje (`learning_curves.png`).\n",
    "     - Un archivo CSV con las predicciones (`predictions.csv`).\n",
    "   \n",
    "* **Metadata**:\n",
    "   - **Definici√≥n**: Los metadatos son la informaci√≥n que describe las propiedades de un `experimento` o un `run`. Incluye los par√°metros registrados, las m√©tricas calculadas, las etiquetas asociadas, y detalles del entorno de entrenamiento, como las versiones de las librer√≠as usadas. Los metadatos ayudan a organizar y entender los resultados, proporcionando contexto sobre las condiciones en las que se entrenaron los modelos.\n",
    "   - **Ejemplo**: Para un `run` que entrena un modelo `VGG16`, los metadatos podr√≠an incluir:\n",
    "     - **Par√°metros:**\n",
    "       - `learning_rate = 0.0001`\n",
    "       - `epochs = 20`\n",
    "       - `batch_size = 64`\n",
    "     - **M√©tricas:**\n",
    "       - `accuracy = 0.92`\n",
    "       - `precision = 0.91`\n",
    "     - **Etiquetas:**\n",
    "       - `experiment_type = hyperparameter_tuning`\n",
    "       - `model_type = CNN`\n",
    "     - **Entorno:** `Versi√≥n de Python 3.9, TensorFlow 2.6, CUDA 11.2.`\n",
    "\n",
    "### 2.1 Componentes Clave del Seguimiento de Experimentos\n",
    "\n",
    "1. **Hip√≥tesis**: La suposici√≥n o prueba que se est√° evaluando. Por ejemplo, \"Si aumento el n√∫mero de √©pocas, la precisi√≥n de validaci√≥n aumentar√°\".\n",
    "\n",
    "2. **Insumos**:\n",
    "   - **C√≥digo**: Scripts y versiones del c√≥digo utilizado para ejecutar el experimento.\n",
    "   - **Datos de Entrenamiento y Validaci√≥n**: Conjuntos de datos utilizados, incluyendo caracter√≠sticas.\n",
    "   - **Arquitectura del Modelo e Hiperpar√°metros**: Configuraci√≥n del modelo, como el tama√±o de la red neuronal y el n√∫mero de √©pocas.\n",
    "\n",
    "3. **Salidas**:\n",
    "   - **M√©tricas de Evaluaci√≥n**: Precisi√≥n, recall, y otras m√©tricas que indican el rendimiento del modelo.\n",
    "   - **Par√°metros del Modelo**: Los par√°metros finales del modelo que se han entrenado.\n",
    "\n",
    "### 2.2 Proceso y Prop√≥sito\n",
    "\n",
    "El desarrollo de un modelo de ML busca encontrar la mejor configuraci√≥n del modelo en t√©rminos de m√©tricas, uso de recursos o tiempo de inferencia, seg√∫n las restricciones del proyecto. Este proceso iterativo implica ejecutar numerosos experimentos, analizar y comparar sus resultados, y probar nuevas ideas para desarrollar la configuraci√≥n de mejor rendimiento. \n",
    "\n",
    "El seguimiento de experimentos permite:\n",
    "- **Registrar Par√°metros**: Por ejemplo, tasa de aprendizaje, tama√±o de lote.\n",
    "- **Rastrear M√©tricas**: Como precisi√≥n, recall.\n",
    "- **Almacenar Artefactos**: Archivos de modelos entrenados, gr√°ficos.\n",
    "- **Guardar Metadatos**: Detalles del entorno, versiones de bibliotecas.\n",
    "\n",
    "Adem√°s, el seguimiento de experimentos facilita la comparaci√≥n de modelos a lo largo del tiempo, la identificaci√≥n de factores que afectan el rendimiento y la colaboraci√≥n con colegas al compartir experimentos.\n",
    "\n",
    "### 2.3 Informaci√≥n Adicional\n",
    "\n",
    "Generalmente, el seguimiento de experimentos incluye:\n",
    "- Scripts utilizados para el experimento.\n",
    "- Archivos de configuraci√≥n del entorno.\n",
    "- Informaci√≥n sobre los datos utilizados (por ejemplo, estad√≠sticas y versiones de los conjuntos de datos).\n",
    "- Configuraciones del modelo y par√°metros de entrenamiento.\n",
    "- M√©tricas de evaluaci√≥n de ML.\n",
    "- Par√°metros del modelo.\n",
    "- Visualizaciones de rendimiento (como matrices de confusi√≥n o curvas ROC).\n",
    "- Predicciones de ejemplo en el conjunto de validaci√≥n (com√∫n en visi√≥n por computadora).\n",
    "\n",
    "El seguimiento de experimentos asegura que cada versi√≥n o configuraci√≥n del modelo est√© bien documentada y sea trazable, facilitando la colaboraci√≥n y la gesti√≥n de modelos a lo largo de m√∫ltiples versiones. Idealmente, esta informaci√≥n debe estar disponible tanto durante como despu√©s de la ejecuci√≥n del experimento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea81b455f38044b",
   "metadata": {},
   "source": [
    "## 3. ¬øLo Necesito?\n",
    "\n",
    "Un rastreador de experimentos permite reproducir cualquier modelo del pasado. Aunque no lo hace solo‚Äîpara lograr una reproducibilidad completa tambi√©n se necesita control de versiones de datos y control de versiones de c√≥digo‚Äîun rastreador de experimentos es la √∫nica herramienta que combina toda la informaci√≥n relevante sobre un modelo.\n",
    "\n",
    "Cuando el rendimiento de un modelo cambia, los rastreadores de experimentos te permiten retroceder y entender por qu√©, lo que a su vez significa que puedes tomar las decisiones correctas para mejorar tu modelo en el futuro.\n",
    "\n",
    "Adem√°s, si tienes un experimento particular que deseas compartir con un colega para obtener su opini√≥n o revisi√≥n, un rastreador de experimentos facilita que tu colega vea no solo el resultado final, sino exactamente c√≥mo llegaste all√≠.\n",
    "\n",
    "Como herramienta tanto para garantizar la reproducibilidad como para habilitar la colaboraci√≥n, el seguimiento de experimentos es una pieza clave de una infraestructura de MLOps.\n",
    "\n",
    "### 3.1 ¬øPor Qu√© Necesitas Rastrear Tus Experimentos de ML?\n",
    "\n",
    "Debido a que peque√±os cambios en las entradas pueden llevar a resultados completamente diferentes, se realizar√°n muchos experimentos para desarrollar el mejor modelo. Sin registrar las entradas y salidas y organizar los experimentos, se puede perder r√°pidamente de vista lo que funcion√≥ y lo que no.\n",
    "\n",
    "Por lo tanto, rastrear tus experimentos de ML de manera organizada puede ayudar en los siguientes aspectos:\n",
    "\n",
    "- **Visi√≥n General**: ¬øCu√°ntos y qu√© experimentos se realizaron?\n",
    "- **Detalles y Reproducibilidad**: ¬øCu√°les fueron los detalles de los experimentos y c√≥mo podemos reproducir los resultados?\n",
    "- **Comparaci√≥n**: ¬øQu√© ideas y cambios llevaron a mejoras?\n",
    "\n",
    "Con la informaci√≥n obtenida, se puede centrar en nuevos enfoques y en mejorar los prototipos en lugar de tratar de dar sentido a una gran cantidad de experimentos desorganizados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2d57ac59fe4313",
   "metadata": {},
   "source": [
    "## 4. ¬øC√≥mo Rastrear Experimentos de Machine Learning?\n",
    "\n",
    "Se puede rastrear experimentos de machine learning de manera manual o autom√°tica utilizando diferentes herramientas. \n",
    "\n",
    "Se podr√≠a realizar el seguimiento manualmente con papel y bol√≠grafo o digitalmente en archivos de texto u hojas de c√°lculo. \n",
    "\n",
    "Tambi√©n puedes automatizar la tarea a√±adiendo funciones de registro a tu c√≥digo o utilizando herramientas modernas de seguimiento de experimentos.\n",
    "\n",
    "Hay algunas opciones, siendo las m√°s populares:\n",
    "\n",
    "* Hojas de c√°lculo y convenci√≥n de nombres (Seguimiento Manual)\n",
    "* Versionando todo con un repositorio de Git\n",
    "* Uso moderno de herramientas para seguimiento de experimentos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc03d8359a988c1c",
   "metadata": {},
   "source": [
    "### 4.1 Seguimiento Manual de Experimentos (¬°Por favor, NO!)\n",
    "\n",
    "Un enfoque com√∫n para el seguimiento de experimentos es crear una hoja de c√°lculo gigante donde se coloca toda la informaci√≥n posible (m√©tricas, par√°metros, etc.) y una estructura de directorios donde las cosas son nombradas de una manera espec√≠fica. Esos nombres suelen terminar siendo muy largos e intrincados, como `model_v1_lr01_batchsize64_no_preprocessing_result_accuracy082.h5`.\n",
    "\n",
    "Cada vez que se ejecuta un experimento, los resultados son revisados y copiados en la hoja de c√°lculo.\n",
    "\n",
    "Este enfoque es sencillo y una buena manera de que los experimentos sean rastreados cuando se est√° comenzando.\n",
    "\n",
    "Sin embargo, se presentan varias desventajas:\n",
    "- **Disciplina y tiempo son requeridos**: Registrar manualmente todos los metadatos relevantes de un experimento requiere disciplina y tiempo.\n",
    "- **Errores son inevitablemente cometidos**: Los errores son inevitables durante el proceso de registro manual.\n",
    "- **Las notas se pueden perder**: Si las notas de los experimentos registradas manualmente se pierden (similar a no usar control de versiones y perder el c√≥digo), muchos, si no todos, los experimentos podr√≠an tener que ser ejecutados nuevamente.\n",
    "- **Escalabilidad es limitada**: Adem√°s, aunque esta tarea tediosa puede ser automatizada, el enfoque no escala bien cuando se necesitan ejecutar muchos experimentos.\n",
    "- **Debe garantizarse que ni t√∫ ni tu equipo sobrescribir√°n accidentalmente la informaci√≥n en la hoja de c√°lculo**. Las hojas de c√°lculo no son f√°ciles de versionar, por lo que si esto sucede, estar√°s en problemas.\n",
    "- **Es necesario recordar rastrearlos**. Las cosas se complican si algo no sucede autom√°ticamente, especialmente cuando hay m√°s personas involucradas.\n",
    "- **Es necesario recordar utilizar las convenciones de nombres**. Si alguien en el equipo comete un error con esto, rastrear los artefactos del experimento (pesos del modelo, gr√°ficos de rendimiento) ser√° doloroso.\n",
    "- **Las carpetas de artefactos deben ser respaldadas independientemente y mantenidas en sincron√≠a con la hoja de c√°lculo**. Incluso si un flujo de trabajo autom√°tico se configura para ejecutarse regularmente, inevitablemente llegar√° un momento en que falle.\n",
    "- **Cuando la hoja de c√°lculo crece, se vuelve menos usable**. Buscar y comparar cientos de experimentos en una hoja de c√°lculo (especialmente si varias personas quieren usarla al mismo tiempo) no es una gran experiencia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baf4026ba0f3256",
   "metadata": {},
   "source": [
    "### 4.2 Seguimiento Autom√°tico de Experimentos Sin Herramientas de Seguimiento de Experimentos\n",
    "\n",
    "Una forma popular de rastrear los experimentos de machine learning es automatizar el tedioso trabajo de registrar todo lo que podr√≠a ser importante, incluyendo funcionalidades de registro en tu c√≥digo.\n",
    "\n",
    "Aunque este enfoque requiere un poco m√°s de esfuerzo para configurarlo en comparaci√≥n con el seguimiento manual de experimentos, es f√°cil de implementar, directo y te ahorra tiempo a largo plazo porque es menos propenso a errores (por ejemplo, cometer errores durante el registro manual, perder notas, etc.) en comparaci√≥n con el seguimiento manual de experimentos.\n",
    "\n",
    "Veamos el flujo de trabajo aproximado del seguimiento autom√°tico de experimentos escribiendo c√≥digo para registrar informaci√≥n en una hoja de c√°lculo.\n",
    "\n",
    "1. **Configuraci√≥n**\n",
    "    Configura una hoja de c√°lculo. Existen varias formas diferentes de a√±adir funcionalidades de registro a tu c√≥digo. En este ejemplo, leeremos la hoja de c√°lculo en un DataFrame de pandas y a√±adiremos una nueva fila para cada experimento.\n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    \n",
    "    log_df = pd.read_csv('log.csv')\n",
    "    ```\n",
    "\n",
    "2. **Registro de Insumos y Salidas**\n",
    "A continuaci√≥n, registra toda la metadata relevante del experimento en un √∫nico diccionario. Luego, puedes a√±adir el diccionario del experimento al DataFrame de pandas como una nueva fila. Al final, puedes guardar el DataFrame de pandas de vuelta en la hoja de c√°lculo. Tambi√©n podr√≠as automatizar el guardado de gr√°ficos relevantes en una carpeta dedicada.\n",
    "    ```python\n",
    "    # Setup a new run\n",
    "    experiment = {'Experiment ID': 1}\n",
    "    \n",
    "    # Log inputs, such as hyperparameters\n",
    "    experiment['learning_rate'] = 1e-3\n",
    "    \n",
    "    # Model development here\n",
    "    # ...\n",
    "    \n",
    "    # Log outputs, such as metrics\n",
    "    experiment['val_acc'] = val_accuracy\n",
    "    \n",
    "    # ...\n",
    "    \n",
    "    # Save experiment details\n",
    "    log_df = log_df.append(experiment, ignore_index = True)\n",
    "    log_df.to_csv('log.csv', index = False)\n",
    "    ```\n",
    "\n",
    "3. **Recuperaci√≥n de Informaci√≥n**\n",
    "   En tu hoja de c√°lculo, ahora puedes buscar, filtrar y ordenar los resultados de diferentes experimentos.\n",
    "    \n",
    "   <img style=\"display: block; margin: auto;\" src=\"./images/tracking-experiment-spreadsheet.png\" width=\"680\" height=\"50\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da72f78c2d925e3e",
   "metadata": {},
   "source": [
    "### 4.3 Seguimiento Automatizado de Experimentos con Herramientas de Seguimiento de Experimentos\n",
    "\n",
    "Finalmente, existen herramientas modernas de seguimiento de experimentos, que son soluciones construidas espec√≠ficamente para rastrear, organizar y comparar experimentos. \n",
    "\n",
    "Hay varias opciones populares, como:\n",
    "https://neptune.ai/blog/best-ml-experiment-tracking-tools\n",
    "\n",
    "\n",
    "* [MLFlow](https://mlflow.org/)\n",
    "* [CometML](https://www.comet.ml/)\n",
    "* [Neptune](https://neptune.ai/)\n",
    "* [Weights & Biases](https://wandb.ai/)\n",
    "* [TensorBoard](https://www.tensorflow.org/tensorboard)\n",
    "* [Otras](https://neptune.ai/blog/best-ml-experiment-tracking-tools):\n",
    "\n",
    "<img style=\"display: block; margin: auto;\" src=\"./images/tracking-experiment-tools.png\" width=\"880\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b23fe2379e7752",
   "metadata": {},
   "source": [
    "## 5. Mejores pr√°cticas para el seguimiento de experimentos de ML\n",
    "\n",
    "Hasta ahora, se ha cubierto qu√© es el seguimiento de experimentos de aprendizaje autom√°tico y por qu√© es importante.\n",
    "\n",
    "Ahora es momento de entrar en detalles.\n",
    "\n",
    "### 5.1 Qu√© deber√≠as rastrear en cualquier experimento de ML:\n",
    "\n",
    "Como se mencion√≥ inicialmente, la informaci√≥n que se quiere rastrear depende en √∫ltima instancia de las caracter√≠sticas del proyecto.\n",
    "\n",
    "Sin embargo, hay algunas cosas que deber√≠as rastrear independientemente del proyecto en el que est√©s trabajando. Estas son:\n",
    "\n",
    "1. **C√≥digo**: Scripts de preprocesamiento, entrenamiento y evaluaci√≥n, notebooks para ingenier√≠a de caracter√≠sticas y otras utilidades. Y, por supuesto, todo el c√≥digo necesario para ejecutar (y re-ejecutar) el experimento.\n",
    "\n",
    "2. **Entorno**: La forma m√°s f√°cil de mantener un registro del entorno es guardar los archivos de configuraci√≥n del entorno como `Dockerfile` (Docker), `requirements.txt` (pip), `pyproject.toml` (por ejemplo, `hatch` y `poetry`), o `conda.yml` (conda). Tambi√©n puedes guardar im√°genes Docker construidas en Docker Hub o en tu propio repositorio de contenedores, pero encuentro m√°s f√°cil guardar archivos de configuraci√≥n.\n",
    "\n",
    "3. **Datos**: Guardar versiones de datos (como un hash o ubicaciones de recursos de datos inmutables) facilita ver en qu√© se entren√≥ tu modelo. Tambi√©n puedes usar herramientas modernas de versionado de datos como `DVC` (y guardar los archivos .dvc en tu herramienta de seguimiento de experimentos).\n",
    "\n",
    "4. **Par√°metros**: Guardar la configuraci√≥n de la ejecuci√≥n de tu experimento es crucial. Ten especial cuidado cuando pases par√°metros a trav√©s de la l√≠nea de comandos (por ejemplo, a trav√©s de argparse, click o hydra), ya que este es un lugar donde puedes olvidar f√°cilmente rastrear informaci√≥n importante. \n",
    "\n",
    "5. **M√©tricas**: Registrar m√©tricas de evaluaci√≥n en conjuntos de entrenamiento, validaci√≥n y prueba para cada ejecuci√≥n es bastante obvio. Pero diferentes frameworks lo hacen de manera diferente, as√≠ que tal vez quieras revisar este art√≠culo en profundidad sobre el seguimiento de m√©tricas de modelos de ML.\n",
    "\n",
    "Mantener un registro de estas cosas te permitir√° reproducir experimentos, realizar depuraciones b√°sicas y entender qu√© sucedi√≥ a un alto nivel.\n",
    "\n",
    "Dicho esto, siempre se pueden registrar m√°s cosas para obtener a√∫n m√°s informaci√≥n. Mientras se mantengan los datos que se rastrean en una estructura agradable, no hace da√±o recopilar informaci√≥n, incluso si no se sabe si podr√≠a ser relevante m√°s adelante. Despu√©s de todo, la mayor√≠a de los metadatos son solo n√∫meros y cadenas que no ocupan mucho espacio.\n",
    "\n",
    "### 5.2 Qu√© m√°s podr√≠as rastrear\n",
    "\n",
    "Veamos algunas cosas adicionales que se podr√≠an querer rastrear al trabajar en un tipo espec√≠fico de proyecto.\n",
    "\n",
    "A continuaci√≥n se presentan algunas recomendaciones para varios tipos de proyectos de ML.\n",
    "\n",
    "#### 5.2.1 Machine Learning\n",
    "\n",
    "- Pesos del modelo\n",
    "- Gr√°ficos de evaluaci√≥n (curvas ROC, matriz de confusi√≥n)\n",
    "- Distribuciones de predicci√≥n\n",
    "\n",
    "#### 5.2.2 Deep Learning\n",
    "\n",
    "- Puntos de control del modelo (tanto durante como despu√©s del entrenamiento)\n",
    "- Normas de gradiente (para controlar problemas de gradiente que desaparece o explota)\n",
    "- Mejores/peores predicciones en el conjunto de validaci√≥n y prueba despu√©s del entrenamiento\n",
    "- Recursos de hardware: √∫til para depurar cargadores de datos y configuraciones multi-GPU\n",
    "\n",
    "#### 5.2.3 Computer Vision\n",
    "\n",
    "- Predicciones del modelo despu√©s de cada √©poca (etiquetas, m√°scaras superpuestas o cuadros delimitadores)\n",
    "\n",
    "#### 5.2.4 Procesamiento del Lenguaje Natural y Modelos de Lenguaje Grande (NLP y LLMs)\n",
    "\n",
    "- Tiempo de inferencia\n",
    "- Prompts (en el caso de LLMs generativos)\n",
    "- M√©tricas de evaluaci√≥n espec√≠ficas (por ejemplo, ROUGE para resumen de texto o BLEU para traducci√≥n entre idiomas)\n",
    "- Tama√±o y dimensiones de incrustaci√≥n, tipo de tokenizador y n√∫mero de cabezas de atenci√≥n (al entrenar modelos de transformadores desde cero)\n",
    "- Importancia de caracter√≠sticas, explicaciones basadas en atenci√≥n o basadas en ejemplos (ver esta visi√≥n general para algoritmos espec√≠ficos y m√°s ideas)\n",
    "\n",
    "#### 5.2.5 Datos Estructurados\n",
    "\n",
    "- Instant√°nea de datos de entrada (`.head()` en DataFrames si est√°s usando pandas)\n",
    "- Importancia de caracter√≠sticas (por ejemplo, importancia de permutaci√≥n)\n",
    "- Explicaciones de predicci√≥n como `SHAP` o gr√°ficos de dependencia parcial (todos est√°n disponibles en DALEX)\n",
    "\n",
    "#### 5.2.6 Reinforcement Learning\n",
    "\n",
    "- Retorno de episodio y duraci√≥n de episodio\n",
    "- Pasos totales del entorno, tiempo de pared, pasos por segundo\n",
    "- P√©rdidas de funci√≥n de valor y pol√≠tica\n",
    "- Estad√≠sticas agregadas sobre m√∫ltiples entornos y/o ejecuciones\n",
    "\n",
    "#### 5.2.7 Optimizaci√≥n de Hiperpar√°metros\n",
    "\n",
    "- Puntuaci√≥n de ejecuci√≥n: la m√©trica que est√°s optimizando despu√©s de cada iteraci√≥n\n",
    "- Par√°metros de ejecuci√≥n: configuraci√≥n de par√°metros probada en cada iteraci√≥n\n",
    "- Mejores par√°metros: mejores par√°metros hasta el momento y mejores par√°metros generales despu√©s de que todas las ejecuciones hayan concluido\n",
    "- Gr√°ficos de comparaci√≥n de par√°metros: hay varias visualizaciones que podr√≠as querer registrar durante o despu√©s del entrenamiento, como gr√°fico de coordenadas paralelas o gr√°fico de corte (todos est√°n disponibles en Optuna, por cierto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53651998fbe8b31",
   "metadata": {},
   "source": [
    "## 6. MLflow\n",
    "\n",
    "<img style=\"display: block; margin: auto;\" src=\"./images/mlflow-logo.png\" width=\"480\" height=\"500\">\n",
    "\n",
    "### 6.1 Introducci√≥n:\n",
    "`MLflow` es una plataforma de c√≥digo abierto indispensable para gestionar el ciclo de vida del aprendizaje autom√°tico. Aborda aspectos clave del proceso de aprendizaje autom√°tico, incluyendo la experimentaci√≥n, la reproducibilidad, la implementaci√≥n y el registro central de modelos.\n",
    "\n",
    "En la pr√°ctica, es solamente un paquete de `Python` que puede ser instalado con `pip`, y contiene 3 m√≥dulos principales:\n",
    "\n",
    "+ Tracking\n",
    "+ Model Registry\n",
    "+ Projects\n",
    "\n",
    "### 6.2 ¬øPor qu√© usar `MLflow`?\n",
    "\n",
    "El proceso de aprendizaje autom√°tico (ML) es complejo, abarcando diversas etapas, desde el preprocesamiento de datos hasta el despliegue del modelo y su monitoreo. Asegurar la productividad y eficiencia a lo largo de este ciclo de vida plantea varios desaf√≠os:\n",
    "\n",
    "- **Gesti√≥n de Experimentos**: Es dif√≠cil llevar un registro de la mir√≠ada de experimentos, especialmente cuando se trabaja con archivos o cuadernos interactivos. Determinar qu√© combinaci√≥n de datos, c√≥digo y par√°metros condujo a un resultado particular puede convertirse en una tarea desalentadora.\n",
    "\n",
    "- **Reproducibilidad**: Asegurar resultados consistentes en diferentes ejecuciones no es trivial. M√°s all√° de solo rastrear versiones de c√≥digo y par√°metros, capturar todo el entorno, incluyendo las dependencias de bibliotecas, es cr√≠tico. Esto se vuelve a√∫n m√°s desafiante al colaborar con otros cient√≠ficos de datos o al escalar el c√≥digo a diferentes plataformas.\n",
    "\n",
    "- **Consistencia en el Despliegue**: Con la pl√©tora de bibliotecas de ML disponibles, a menudo no hay una forma estandarizada de empaquetar y desplegar modelos. Las soluciones personalizadas pueden llevar a inconsistencias, y el v√≠nculo crucial entre un modelo y el c√≥digo y par√°metros que lo produjeron podr√≠a perderse.\n",
    "\n",
    "- **Gesti√≥n de Modelos**: A medida que los equipos de ciencia de datos producen numerosos modelos, gestionar, probar y desplegar continuamente estos modelos se convierte en un obst√°culo significativo. Sin una plataforma centralizada, gestionar los ciclos de vida de los modelos se vuelve inmanejable.\n",
    "\n",
    "- **Agnosticismo de Biblioteca**: Aunque las bibliotecas individuales de ML podr√≠an ofrecer soluciones a algunos de los desaf√≠os, lograr los mejores resultados a menudo implica experimentar a trav√©s de m√∫ltiples bibliotecas. Una plataforma que ofrezca compatibilidad con varias bibliotecas mientras asegura que los modelos sean utilizables como \"cajas negras\" reproducibles es esencial.\n",
    "\n",
    "MLflow aborda estos desaf√≠os ofreciendo una plataforma unificada dise√±ada para todo el ciclo de vida del ML. Sus beneficios incluyen:\n",
    "\n",
    "- **Trazabilidad**: Con herramientas como el Servidor de Seguimiento, cada experimento se registra, asegurando que los equipos puedan rastrear y entender la evoluci√≥n de los modelos.\n",
    "\n",
    "- **Consistencia**: Ya sea accediendo a modelos a trav√©s de las Implementaciones de MLflow para LLMs o estructurando proyectos con Recetas de `MLflow`, `MLflow` promueve un enfoque consistente, reduciendo tanto la curva de aprendizaje como los posibles errores.\n",
    "\n",
    "- **Flexibilidad**: El dise√±o agn√≥stico de bibliotecas de `MLflow` asegura compatibilidad con una amplia gama de bibliotecas de machine learning. Ofrece soporte integral a trav√©s de diferentes lenguajes de programaci√≥n, respaldado por una robusta API REST, CLI y APIs para Python, R y Java.\n",
    "\n",
    "Al simplificar el complejo paisaje de los flujos de trabajo de ML, `MLflow` empodera a los cient√≠ficos de datos y desarrolladores a centrarse en construir y refinar modelos, asegurando un camino √°gil desde la experimentaci√≥n hasta la producci√≥n.\n",
    "\n",
    "###  6.3 ¬øQui√©n usa MLFlow?\n",
    "\n",
    "Los Cient√≠ficos de Datos aprovechan `MLflow` para:\n",
    "\n",
    "- Seguimiento de experimentos y persistencia de pruebas de hip√≥tesis.\n",
    "- Estructuraci√≥n de c√≥digo para una mejor reproducibilidad.\n",
    "- Empaquetado de modelos y gesti√≥n de dependencias.\n",
    "- Evaluar los l√≠mites de selecci√≥n de ajuste de hiperpar√°metros.\n",
    "- Comparar los resultados de re-entrenamiento de modelos a lo largo del tiempo.\n",
    "- Revisar y seleccionar modelos √≥ptimos para el despliegue.\n",
    "\n",
    "Los Profesionales de MLOps utilizan `MLflow` para:\n",
    "\n",
    "- Gestionar los ciclos de vida de los modelos entrenados, tanto antes como despu√©s del despliegue.\n",
    "- Desplegar modelos de forma segura en entornos de producci√≥n.\n",
    "- Auditar y revisar modelos candidatos antes del despliegue.\n",
    "- Gestionar las dependencias de despliegue.\n",
    "\n",
    "Los Gerentes de Ciencia de Datos interact√∫an con `MLflow` mediante:\n",
    "\n",
    "- Revisi√≥n de los resultados de la experimentaci√≥n y las actividades de modelado.\n",
    "- Colaboraci√≥n con equipos para asegurar que los objetivos de modelado se alineen con los objetivos empresariales.\n",
    "\n",
    "Los Usuarios de Ingenier√≠a de Prompts usan `MLflow` para:\n",
    "\n",
    "- Evaluar y experimentar con modelos de lenguaje de gran escala.\n",
    "- Crear prompts personalizados y persistir sus creaciones candidatas.\n",
    "- Decidir sobre el mejor modelo base adecuado para los requisitos espec√≠ficos de su proyecto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eee0efe2983ce5",
   "metadata": {},
   "source": [
    "### 6.4 `MLflow` Tracking\n",
    "\n",
    "`MLflow Tracking` es uno de los componentes principales de servicio de `MLflow`\n",
    "\n",
    "<img style=\"display: block; margin: auto;\" src=\"./images/mlflow-tracking-basics.png\" width=\"880\" height=\"500\">\n",
    "\n",
    "\n",
    "<img style=\"display: block; margin: auto;\" src=\"./images/mlflow-run-comparison.png\" width=\"880\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a4fa2607fa5f1f",
   "metadata": {},
   "source": [
    "## üß© 7. Hands-On ‚Äî Tracking de experimentos con `MLflow`\n",
    "https://mlflow.org/docs/latest/tracking/tracking-api.html\n",
    "\n",
    "En esta pr√°ctica aprenderemos a **configurar desde cero** un peque√±o proyecto para hacer _tracking_ de experimentos con MLflow.\n",
    "\n",
    "üí° Este mismo repositorio lo usaremos durante el resto del curso, por lo tanto:\n",
    "- Todo lo haremos sobre una **rama nueva** (no en `main`).\n",
    "- Trabajaremos con **uv** para gestionar dependencias.\n",
    "- Dejaremos la **estructura base del proyecto** lista para ampliarla m√°s adelante.\n",
    "\n",
    "### 7.1 Crear el repositorio y la rama de trabajo üêô\n",
    "\n",
    "1. Entra a tu cuenta de **GitHub** y crea un nuevo repositorio llamado: `nyc-taxi-predictions-2025`\n",
    "2. En tu terminal, ejecuta los comandos para:\n",
    "- Clonar el repositorio en tu equipo.\n",
    "- Cambiarte al directorio del proyecto.\n",
    "- Crear una rama de trabajo exclusiva para esta clase. `git checkout -b feat/01-mlflow-tracking-basics`\n",
    "\n",
    "### 7.2 Inicializar el entorno con `uv` üß∞\n",
    "\n",
    "Ahora configuraremos el entorno del proyecto con **uv**: crearemos el ambiente virtual, instalaremos las dependencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236ecc469df0d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar el proyecto con uv\n",
    "uv init --python 3.11\n",
    "\n",
    "# Crear y activar entorno virtual (si uv no lo hace autom√°ticamente)\n",
    "uv venv\n",
    "source .venv/bin/activate   # macOS / Linux\n",
    "# o:\n",
    "# source .venv/Scripts/activate  # Windows / Git Bash\n",
    "\n",
    "# Instalar librer√≠as base\n",
    "uv add mlflow scikit-learn pandas pyarrow fastparquet matplotlib jupyterlab ipykernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7395b5d6cb01f5",
   "metadata": {},
   "source": [
    "### 7.3 Descargar los datos üöï\n",
    "Descargaremos los archivos de datos del **NYC Taxi Dataset** (enero y febrero 2025).\n",
    "\n",
    "```bash\n",
    "# Crear carpeta data si no existe\n",
    "mkdir -p data\n",
    "\n",
    "# Descargar datasets con curl\n",
    "curl -o ./data/green_tripdata_2025-01.parquet https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2025-01.parquet\n",
    "curl -o ./data/green_tripdata_2025-02.parquet https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2025-02.parquet\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c149530b1c2a692f",
   "metadata": {},
   "source": [
    "### 7.4 Preparar datos y definir features üîß\n",
    "Importaremos los datos y haremos un peque√±o preprocesamiento antes de iniciar el tracking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b478355b9a0769e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "def read_dataframe(path):\n",
    "    df = pd.read_parquet(path)\n",
    "    df[\"duration\"] = (df.lpep_dropoff_datetime - df.lpep_pickup_datetime).dt.total_seconds() / 60\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "    df[[\"PULocationID\", \"DOLocationID\"]] = df[[\"PULocationID\", \"DOLocationID\"]].astype(str)\n",
    "    return df\n",
    "\n",
    "df_train = read_dataframe(\"data/green_tripdata_2025-01.parquet\")\n",
    "df_val = read_dataframe(\"data/green_tripdata_2025-02.parquet\")\n",
    "\n",
    "df_train[\"PU_DO\"] = df_train[\"PULocationID\"] + \"_\" + df_train[\"DOLocationID\"]\n",
    "df_val[\"PU_DO\"] = df_val[\"PULocationID\"] + \"_\" + df_val[\"DOLocationID\"]\n",
    "\n",
    "categorical = [\"PU_DO\"]\n",
    "numerical = [\"trip_distance\"]\n",
    "\n",
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(df_train[categorical + numerical].to_dict(orient=\"records\"))\n",
    "X_val = dv.transform(df_val[categorical + numerical].to_dict(orient=\"records\"))\n",
    "\n",
    "y_train = df_train[\"duration\"].values\n",
    "y_val = df_val[\"duration\"].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbee4ef18f331db",
   "metadata": {},
   "source": [
    "### 7.5 Tracking con `MLflow` üöÄ\n",
    "\n",
    "Configuraremos MLflow para:\n",
    "- Definir un experimento.\n",
    "- Iniciar un run.\n",
    "- Registrar par√°metros, m√©tricas y modelo.\n",
    "- Visualizar resultados en la UI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22a3fa6bf063568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"class-nyc-taxi-experiment\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"lasso_alpha_0.1\"):\n",
    "    alpha = 0.1\n",
    "    mlflow.log_param(\"alpha\", alpha)\n",
    "\n",
    "    model = Lasso(alpha=alpha)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_val)\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "    print(f\"‚úÖ Run finalizado. RMSE = {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5a1205b42df178",
   "metadata": {},
   "source": [
    "### 7.6 Visualizar el tracking server üîç\n",
    "\n",
    "Ejecuta en una terminal **aparte**:\n",
    "\n",
    "```bash\n",
    "mlflow ui --backend-store-uri sqlite:///mlflow.db\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad366d86936b5dc4",
   "metadata": {},
   "source": [
    "### 7.7 Cierre y entrega üèÅ\n",
    "\n",
    "1. Guarda tus cambios y haz commit desde tu rama:\n",
    "\n",
    "```bash\n",
    "git add .\n",
    "git commit -m \"feat: first MLflow tracking experiment\"\n",
    "git push origin feat/01-mlflow-tracking-basics\n",
    "```\n",
    "\n",
    "2. Abre un Pull Request (PR) en GitHub y apruebalo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711c389373dbc04d",
   "metadata": {},
   "source": [
    "### 7.8 Tips para hacer Tracking con `MLflow`\n",
    "\n",
    "https://mlflow.org/docs/latest/tracking/tracking-api.html#tracking-tips"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
